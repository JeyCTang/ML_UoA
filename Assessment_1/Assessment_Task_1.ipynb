{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CS5062_ASSESSMENT1_ZHIXI_TANG__52097136\n",
    "\n",
    "Student: ZHIXI TANG\n",
    "Student ID: 52097136\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This .ipynb file include the source code and detailed explanation of CS5062 Assessment 1. It can be run on local machine with\n",
    "required environment or Google Colab.\n",
    "\n",
    "**Run on local machine:**\n",
    "\n",
    "* System:\n",
    "* Python Version:\n",
    "* IDE: Pycharm:\n",
    "* Required packages: see `requirements.txt` or use command `$ pip install -r requirements.txt`\n",
    "\n",
    "**Run on Colab:**\n",
    "\n",
    "Simply uploading this .ipynb file on Google Colab then feel free to play it."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Task 1\n",
    "\n",
    "### Task 1 - A: Data Import"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": "     Variety     S_1   S_2     S_3   S_4      M_1   M_2    M_3        W_1  \\\n0          1  4.0900  15.3  396.90  4.98  0.00632  18.0  6.575   2.381979   \n1          2  4.9671  17.8  396.90  9.14  0.02731   0.0  6.421   7.071148   \n2          2  4.9671  17.8  392.83  4.03  0.02729   0.0  7.185   6.896941   \n3          3  6.0622  18.7  394.63  2.94  0.03237   0.0  6.998   2.237817   \n4          3  6.0622  18.7  396.90  5.33  0.06905   0.0  7.147   1.979327   \n..       ...     ...   ...     ...   ...      ...   ...    ...        ...   \n501        1  2.4786  21.0  391.99  9.67  0.06263   0.0  6.593  11.774062   \n502        1  2.2875  21.0  396.90  9.08  0.04527   0.0  6.120  11.785249   \n503        1  2.1675  21.0  396.90  5.64  0.06076   0.0  6.976  11.854205   \n504        1  2.3889  21.0  393.45  6.48  0.10959   0.0  6.794  11.765196   \n505        1  2.5050  21.0  396.90  7.88  0.04741   0.0  6.030  12.007563   \n\n          W_2   W_3         W_4  Yield  \n0    0.475522  65.2  296.350195   24.0  \n1    0.509165  78.9  241.620198   21.6  \n2    0.580673  61.1  241.551476   34.7  \n3    0.491539  45.8  222.023994   33.4  \n4    0.103660  54.2  221.723972   36.2  \n..        ...   ...         ...    ...  \n501  0.565469  69.1  272.952382   22.4  \n502  0.562102  76.7  273.264306   20.6  \n503  0.777569  91.0  273.421726   23.9  \n504  0.679057  89.3  273.913622   22.0  \n505  0.615699  80.8  273.623418   11.9  \n\n[506 rows x 13 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variety</th>\n      <th>S_1</th>\n      <th>S_2</th>\n      <th>S_3</th>\n      <th>S_4</th>\n      <th>M_1</th>\n      <th>M_2</th>\n      <th>M_3</th>\n      <th>W_1</th>\n      <th>W_2</th>\n      <th>W_3</th>\n      <th>W_4</th>\n      <th>Yield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>4.0900</td>\n      <td>15.3</td>\n      <td>396.90</td>\n      <td>4.98</td>\n      <td>0.00632</td>\n      <td>18.0</td>\n      <td>6.575</td>\n      <td>2.381979</td>\n      <td>0.475522</td>\n      <td>65.2</td>\n      <td>296.350195</td>\n      <td>24.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>4.9671</td>\n      <td>17.8</td>\n      <td>396.90</td>\n      <td>9.14</td>\n      <td>0.02731</td>\n      <td>0.0</td>\n      <td>6.421</td>\n      <td>7.071148</td>\n      <td>0.509165</td>\n      <td>78.9</td>\n      <td>241.620198</td>\n      <td>21.6</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>4.9671</td>\n      <td>17.8</td>\n      <td>392.83</td>\n      <td>4.03</td>\n      <td>0.02729</td>\n      <td>0.0</td>\n      <td>7.185</td>\n      <td>6.896941</td>\n      <td>0.580673</td>\n      <td>61.1</td>\n      <td>241.551476</td>\n      <td>34.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>6.0622</td>\n      <td>18.7</td>\n      <td>394.63</td>\n      <td>2.94</td>\n      <td>0.03237</td>\n      <td>0.0</td>\n      <td>6.998</td>\n      <td>2.237817</td>\n      <td>0.491539</td>\n      <td>45.8</td>\n      <td>222.023994</td>\n      <td>33.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3</td>\n      <td>6.0622</td>\n      <td>18.7</td>\n      <td>396.90</td>\n      <td>5.33</td>\n      <td>0.06905</td>\n      <td>0.0</td>\n      <td>7.147</td>\n      <td>1.979327</td>\n      <td>0.103660</td>\n      <td>54.2</td>\n      <td>221.723972</td>\n      <td>36.2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>501</th>\n      <td>1</td>\n      <td>2.4786</td>\n      <td>21.0</td>\n      <td>391.99</td>\n      <td>9.67</td>\n      <td>0.06263</td>\n      <td>0.0</td>\n      <td>6.593</td>\n      <td>11.774062</td>\n      <td>0.565469</td>\n      <td>69.1</td>\n      <td>272.952382</td>\n      <td>22.4</td>\n    </tr>\n    <tr>\n      <th>502</th>\n      <td>1</td>\n      <td>2.2875</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>9.08</td>\n      <td>0.04527</td>\n      <td>0.0</td>\n      <td>6.120</td>\n      <td>11.785249</td>\n      <td>0.562102</td>\n      <td>76.7</td>\n      <td>273.264306</td>\n      <td>20.6</td>\n    </tr>\n    <tr>\n      <th>503</th>\n      <td>1</td>\n      <td>2.1675</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>5.64</td>\n      <td>0.06076</td>\n      <td>0.0</td>\n      <td>6.976</td>\n      <td>11.854205</td>\n      <td>0.777569</td>\n      <td>91.0</td>\n      <td>273.421726</td>\n      <td>23.9</td>\n    </tr>\n    <tr>\n      <th>504</th>\n      <td>1</td>\n      <td>2.3889</td>\n      <td>21.0</td>\n      <td>393.45</td>\n      <td>6.48</td>\n      <td>0.10959</td>\n      <td>0.0</td>\n      <td>6.794</td>\n      <td>11.765196</td>\n      <td>0.679057</td>\n      <td>89.3</td>\n      <td>273.913622</td>\n      <td>22.0</td>\n    </tr>\n    <tr>\n      <th>505</th>\n      <td>1</td>\n      <td>2.5050</td>\n      <td>21.0</td>\n      <td>396.90</td>\n      <td>7.88</td>\n      <td>0.04741</td>\n      <td>0.0</td>\n      <td>6.030</td>\n      <td>12.007563</td>\n      <td>0.615699</td>\n      <td>80.8</td>\n      <td>273.623418</td>\n      <td>11.9</td>\n    </tr>\n  </tbody>\n</table>\n<p>506 rows Ã— 13 columns</p>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy.random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "df = pd.read_csv('./data/soybean_tabular.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Provide short statistical summary (mean, range, standard deviations, min/max, median, and 25%/50%/75% percentile),\n",
    "describe the data provided identifying and rectifying any missing values."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "              S_1         S_2         S_3         S_4         M_1         M_2  \\\ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \nmean     3.795043   18.455534  356.674032   12.653063    3.613524   11.363636   \nstd      2.105710    2.164946   91.294864    7.141062    8.601545   23.322453   \nmin      1.129600   12.600000    0.320000    1.730000    0.006320    0.000000   \n25%      2.100175   17.400000  375.377500    6.950000    0.082045    0.000000   \n50%      3.207450   19.050000  391.440000   11.360000    0.256510    0.000000   \n75%      5.188425   20.200000  396.225000   16.955000    3.677083   12.500000   \nmax     12.126500   22.000000  396.900000   37.970000   88.976200  100.000000   \n\n              M_3         W_1         W_2         W_3         W_4       Yield  \ncount  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000  \nmean     6.284634   11.131488    0.551258   68.574901  408.252839   22.532806  \nstd      0.702617    6.868654    0.181693   28.148861  168.530578    9.197104  \nmin      3.561000    0.472905    0.103660    2.900000  186.765075    5.000000  \n25%      5.885500    5.149096    0.422286   45.025000  278.745884   17.025000  \n50%      6.208500    9.588040    0.528133   77.500000  330.467783   21.200000  \n75%      6.623500   18.094315    0.668573   94.075000  665.354401   25.000000  \nmax      8.780000   28.074197    1.158538  100.000000  711.210992   50.000000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>S_1</th>\n      <th>S_2</th>\n      <th>S_3</th>\n      <th>S_4</th>\n      <th>M_1</th>\n      <th>M_2</th>\n      <th>M_3</th>\n      <th>W_1</th>\n      <th>W_2</th>\n      <th>W_3</th>\n      <th>W_4</th>\n      <th>Yield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n      <td>506.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>3.795043</td>\n      <td>18.455534</td>\n      <td>356.674032</td>\n      <td>12.653063</td>\n      <td>3.613524</td>\n      <td>11.363636</td>\n      <td>6.284634</td>\n      <td>11.131488</td>\n      <td>0.551258</td>\n      <td>68.574901</td>\n      <td>408.252839</td>\n      <td>22.532806</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>2.105710</td>\n      <td>2.164946</td>\n      <td>91.294864</td>\n      <td>7.141062</td>\n      <td>8.601545</td>\n      <td>23.322453</td>\n      <td>0.702617</td>\n      <td>6.868654</td>\n      <td>0.181693</td>\n      <td>28.148861</td>\n      <td>168.530578</td>\n      <td>9.197104</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.129600</td>\n      <td>12.600000</td>\n      <td>0.320000</td>\n      <td>1.730000</td>\n      <td>0.006320</td>\n      <td>0.000000</td>\n      <td>3.561000</td>\n      <td>0.472905</td>\n      <td>0.103660</td>\n      <td>2.900000</td>\n      <td>186.765075</td>\n      <td>5.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>2.100175</td>\n      <td>17.400000</td>\n      <td>375.377500</td>\n      <td>6.950000</td>\n      <td>0.082045</td>\n      <td>0.000000</td>\n      <td>5.885500</td>\n      <td>5.149096</td>\n      <td>0.422286</td>\n      <td>45.025000</td>\n      <td>278.745884</td>\n      <td>17.025000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>3.207450</td>\n      <td>19.050000</td>\n      <td>391.440000</td>\n      <td>11.360000</td>\n      <td>0.256510</td>\n      <td>0.000000</td>\n      <td>6.208500</td>\n      <td>9.588040</td>\n      <td>0.528133</td>\n      <td>77.500000</td>\n      <td>330.467783</td>\n      <td>21.200000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>5.188425</td>\n      <td>20.200000</td>\n      <td>396.225000</td>\n      <td>16.955000</td>\n      <td>3.677083</td>\n      <td>12.500000</td>\n      <td>6.623500</td>\n      <td>18.094315</td>\n      <td>0.668573</td>\n      <td>94.075000</td>\n      <td>665.354401</td>\n      <td>25.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>12.126500</td>\n      <td>22.000000</td>\n      <td>396.900000</td>\n      <td>37.970000</td>\n      <td>88.976200</td>\n      <td>100.000000</td>\n      <td>8.780000</td>\n      <td>28.074197</td>\n      <td>1.158538</td>\n      <td>100.000000</td>\n      <td>711.210992</td>\n      <td>50.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = df.iloc[:, 1:]\n",
    "\n",
    "# range\n",
    "df1.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The statistical description is shown above. As the feature `variety` is just a number to represent corp variety, we do not\n",
    "have to count its means, std, min, etc.\n",
    "\n",
    "From the above data we can see in the column `M_2`, there are some values are missed. The dataset has used $0$ to replace\n",
    "these missed values.\n",
    "\n",
    "However, to a certain variety of crops, there maybe a certain result corresponding to its features and yield,\n",
    "therefore, we will get the statistical description of different varieties of corps separately."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "24    132\n5     115\n4     110\n3      38\n6      26\n2      24\n8      24\n1      20\n7      17\nName: Variety, dtype: int64"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how many varieties in corps\n",
    "df['Variety'].value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def show_describe(dataframe, variety_num):\n",
    "    \"\"\"\"The variety_num can only be one of [24, 5, 4, 3, 6, 2, 8, 1, 7]\"\"\"\n",
    "    df_v = dataframe.loc[dataframe['Variety'] == variety_num]\n",
    "    return  df_v.describe()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def DiffYield(dataframe):\n",
    "    varieties = [24, 5, 4, 3, 6, 2, 8, 1, 7]\n",
    "    index = ['mean', 'std', 'min', '25%', '50%', '75%', 'max']\n",
    "    v_names = []\n",
    "    data = {}\n",
    "\n",
    "    for i in varieties:\n",
    "        df_v = show_describe(dataframe, i)  # get the describe info of a single variety\n",
    "        corp_yield = df_v.iloc[1:, -1].values\n",
    "        exec(f\"data['Variety_{i}'] = corp_yield\")\n",
    "    yield_df = pd.DataFrame(data, index=index)\n",
    "\n",
    "    return yield_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "RangeIndex(start=1, stop=506, step=1)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.iloc[1:, -1]\n",
    "df.iloc[1:, -1].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "      Variety_24  Variety_5  Variety_4  Variety_3  Variety_6  Variety_2  \\\nmean   16.403788  25.706957  21.387273  27.928947  20.976923  26.833333   \nstd     8.539745   9.328401   6.957883   8.324692   2.312801   7.874376   \nmin     5.000000  11.800000   7.000000  14.400000  16.800000  15.700000   \n25%    11.225000  19.500000  17.575000  21.125000  18.900000  21.400000   \n50%    14.400000  23.000000  20.450000  26.500000  21.200000  23.850000   \n75%    19.900000  30.000000  23.650000  34.525000  23.025000  33.225000   \nmax    50.000000  50.000000  50.000000  50.000000  24.800000  43.800000   \n\n      Variety_8  Variety_1  Variety_7  \nmean  30.358333  24.365000  27.105882  \nstd    9.727724   8.024454   6.493215  \nmin   16.000000  11.900000  17.600000  \n25%   23.825000  20.475000  24.300000  \n50%   28.250000  22.200000  26.200000  \n75%   33.175000  27.225000  29.600000  \nmax   50.000000  50.000000  42.800000  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variety_24</th>\n      <th>Variety_5</th>\n      <th>Variety_4</th>\n      <th>Variety_3</th>\n      <th>Variety_6</th>\n      <th>Variety_2</th>\n      <th>Variety_8</th>\n      <th>Variety_1</th>\n      <th>Variety_7</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>mean</th>\n      <td>16.403788</td>\n      <td>25.706957</td>\n      <td>21.387273</td>\n      <td>27.928947</td>\n      <td>20.976923</td>\n      <td>26.833333</td>\n      <td>30.358333</td>\n      <td>24.365000</td>\n      <td>27.105882</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>8.539745</td>\n      <td>9.328401</td>\n      <td>6.957883</td>\n      <td>8.324692</td>\n      <td>2.312801</td>\n      <td>7.874376</td>\n      <td>9.727724</td>\n      <td>8.024454</td>\n      <td>6.493215</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>5.000000</td>\n      <td>11.800000</td>\n      <td>7.000000</td>\n      <td>14.400000</td>\n      <td>16.800000</td>\n      <td>15.700000</td>\n      <td>16.000000</td>\n      <td>11.900000</td>\n      <td>17.600000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>11.225000</td>\n      <td>19.500000</td>\n      <td>17.575000</td>\n      <td>21.125000</td>\n      <td>18.900000</td>\n      <td>21.400000</td>\n      <td>23.825000</td>\n      <td>20.475000</td>\n      <td>24.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>14.400000</td>\n      <td>23.000000</td>\n      <td>20.450000</td>\n      <td>26.500000</td>\n      <td>21.200000</td>\n      <td>23.850000</td>\n      <td>28.250000</td>\n      <td>22.200000</td>\n      <td>26.200000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>19.900000</td>\n      <td>30.000000</td>\n      <td>23.650000</td>\n      <td>34.525000</td>\n      <td>23.025000</td>\n      <td>33.225000</td>\n      <td>33.175000</td>\n      <td>27.225000</td>\n      <td>29.600000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>24.800000</td>\n      <td>43.800000</td>\n      <td>50.000000</td>\n      <td>50.000000</td>\n      <td>42.800000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DiffYield(df)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "From above table we can tell that to different varieties of corps, the yield is also different. For example, The Max yield of\n",
    "`Variety_6` is just 24.8 which is much lower than other varieties. According to the mean of `variety_24`, we can tell its average\n",
    "yield is much lower than other varieties. Therefore, we can conclude that the variety of corps affects its yield."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1 - B: Data pre-processing\n",
    "\n",
    "In this section, we will split dataset to train, validation, test with rate of 6:2:2. At the same time, we will try our\n",
    "best to ensure the fairness and uniformity of data. According to the conclusion of `Task 1 - A`, we know that the variety\n",
    "of corps affects its yield. Therefore, we will take samples from each variety at a ratio of 6:2:2 (train:validation:test),\n",
    "and then compose the datasets. In this case, we can assure as much as possible that in each set of data, the variety proportions of\n",
    "corps are approximately equal."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def extract_df_by_variety(dataframe):\n",
    "    \"\"\"Split dataframe based on varieties, return all dataframes with dictionary\"\"\"\n",
    "    varieties = [24, 5, 4, 3, 6, 2, 8, 1, 7]\n",
    "    extracted_df = {}\n",
    "    for variety in varieties:\n",
    "        df_s = dataframe.loc[dataframe['Variety'] == variety]\n",
    "        # exec(f\"extracted_df['Variety_{variety}'] = df_s\")\n",
    "        extracted_df[variety] = df_s\n",
    "    return extracted_df\n",
    "\n",
    "def split_single_dataset(dataframe):\n",
    "    \"\"\"split particular dataset to train:val:test = 6:2:2\"\"\"\n",
    "    train_set = dataframe.sample(frac=0.6, random_state=0, axis=0)\n",
    "    rest_set = dataframe[~dataframe.index.isin(train_set.index)]\n",
    "    test_set = rest_set.sample(frac=0.5, random_state=0, axis=0)\n",
    "    val_set = rest_set[~rest_set.index.isin(test_set.index)]\n",
    "\n",
    "    return train_set, test_set, val_set\n",
    "\n",
    "def stratified_sampling(dataframe):\n",
    "    \"\"\"\"Combine above functions, input the dataframe, return the stratified sampled datasets\"\"\"\n",
    "    extracted_dfs = extract_df_by_variety(dataframe)\n",
    "    train_sets, test_sets, val_sets = [], [], []\n",
    "    for _df in extracted_dfs.values():\n",
    "        train_set, test_set, val_set = split_single_dataset(_df)\n",
    "        train_sets.append(train_set)\n",
    "        test_sets.append(test_set)\n",
    "        val_sets.append(val_set)\n",
    "    p_train = np.array(pd.concat(train_sets).sample(frac=1), dtype='float32')\n",
    "    p_test = np.array(pd.concat(test_sets).sample(frac=1), dtype='float32')\n",
    "    p_val = np.array(pd.concat(val_sets).sample(frac=1), dtype='float32')\n",
    "\n",
    "    return p_train, p_test, p_val\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# get train, validation, test datasets\n",
    "train_set, test_set, val_set = stratified_sampling(df)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def tensor_generator(dataset):\n",
    "    \"\"\"input stratified sampled dataset, return variable x and result y\"\"\"\n",
    "    x = torch.tensor(dataset[...,:12])\n",
    "    y = torch.tensor(dataset[...,12:])\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1.0000e+00, 9.0892e+00, 1.8200e+01,  ..., 2.4773e-01, 3.1500e+01,\n         2.4052e+02],\n        [4.0000e+00, 3.3175e+00, 1.8400e+01,  ..., 3.5898e-01, 8.2500e+01,\n         3.0440e+02],\n        [4.0000e+00, 3.6659e+00, 1.8200e+01,  ..., 3.4383e-01, 2.8900e+01,\n         2.6969e+02],\n        ...,\n        [2.4000e+01, 2.5182e+00, 2.0200e+01,  ..., 9.2563e-01, 8.8000e+01,\n         6.6515e+02],\n        [5.0000e+00, 3.4211e+00, 1.6400e+01,  ..., 5.5014e-01, 8.5100e+01,\n         2.7610e+02],\n        [2.4000e+01, 2.5052e+00, 2.0200e+01,  ..., 6.8719e-01, 9.1000e+01,\n         6.6622e+02]])"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get tensors\n",
    "\n",
    "x_train, y_train = tensor_generator(train_set)\n",
    "x_val, y_val = tensor_generator(val_set)\n",
    "x_test, y_test = tensor_generator(test_set)\n",
    "\n",
    "x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "According to the first table shown in `Task 1 - A`, we can tell that the values of different features have observable difference, for example,\n",
    "in the first example, the value of feature `S_3` is 369.90, the value of feature `W_2` is 0.475522. To eliminate the gradient descent majorly\n",
    "depends on some features, we will do z-score normalization to the variable $X$. As we know, the formula of z-score is: $\\hat X = \\frac{X-\\mu}{\\epsilon}$,\n",
    "where $\\hat X$ is the normalized variable $X$, $\\mu$ is the mean of $X$, $\\epsilon$ is the standard deviation of $X$. Therefore, we can define\n",
    "function as the following."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# def normalization(dataframe, columns):\n",
    "#     sc_set = StandardScaler().fit_transform(dataframe)\n",
    "#     return pd.DataFrame(data=sc_set, columns=columns)\n",
    "def normalization_x(x, y):\n",
    "    \"\"\"Input a tensor, return the z-score normalized tensor\"\"\"\n",
    "    mean = torch.mean(x)\n",
    "    std = torch.std(x)\n",
    "    normed_x = (x - mean) / std\n",
    "    normed_y = (y - mean) / std\n",
    "    return normed_x, normed_y\n",
    "\n",
    "# normalize X\n",
    "normed_x_train, normed_y_train = normalization_x(x_train, y_train)\n",
    "normed_x_val, normed_y_val = normalization_x(x_val, y_val)\n",
    "normed_x_test, normed_y_test = normalization_x(x_test, y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i_batch: 0\t-----batched_sample: [tensor([[-0.4810, -0.4823, -0.3672,  2.0120, -0.3671, -0.4994, -0.5077, -0.4705,\n",
      "         -0.4529, -0.5049,  0.1487,  1.5498],\n",
      "        [-0.4810, -0.4679, -0.4007,  2.1209, -0.4583, -0.5074, -0.5077, -0.4639,\n",
      "         -0.4141, -0.5049, -0.1665,  1.4284],\n",
      "        [-0.3471, -0.4885, -0.3726, -0.3605, -0.3930, -0.4825, -0.5077, -0.4679,\n",
      "         -0.3868, -0.5029,  0.0590,  3.9495],\n",
      "        [-0.4743, -0.4495, -0.3880,  2.1415, -0.4755, -0.5076,  0.0945, -0.4592,\n",
      "         -0.4994, -0.5059, -0.3612,  1.0049],\n",
      "        [-0.4810, -0.4841, -0.3846,  2.1367, -0.4384, -0.5050, -0.5077, -0.4650,\n",
      "         -0.4404, -0.5043, -0.0581,  1.5317],\n",
      "        [-0.3471, -0.4946, -0.3726, -0.1014, -0.3466, -0.4452, -0.5077, -0.4650,\n",
      "         -0.3867, -0.5037,  0.1319,  3.9508],\n",
      "        [-0.4676, -0.4588, -0.3967,  1.9795, -0.4441, -0.5074, -0.1564, -0.4638,\n",
      "         -0.4723, -0.5040, -0.3545,  1.4564],\n",
      "        [-0.4810, -0.4813, -0.3846,  2.1448, -0.4308, -0.5060, -0.5077, -0.4696,\n",
      "         -0.4425, -0.5045,  0.0122,  1.5224],\n",
      "        [-0.4810, -0.4832, -0.3860,  2.1442, -0.4662, -0.5075, -0.3204, -0.4662,\n",
      "         -0.4084, -0.5054, -0.3144,  1.2968],\n",
      "        [-0.4743, -0.4944, -0.4207,  2.1179, -0.4378, -0.5026, -0.3739, -0.4705,\n",
      "         -0.4824, -0.5027, -0.0875,  1.2585]]), tensor([[-0.4167],\n",
      "        [-0.3264],\n",
      "        [-0.3806],\n",
      "        [-0.2709],\n",
      "        [-0.3532],\n",
      "        [-0.4442],\n",
      "        [-0.3418],\n",
      "        [-0.3993],\n",
      "        [-0.3405],\n",
      "        [-0.3552]])]\n",
      "i_batch: 1\t-----batched_sample: [tensor([[-0.4743, -0.4772, -0.4060,  2.0539, -0.4772, -0.5069, -0.2066, -0.4639,\n",
      "         -0.4849, -0.5048, -0.3130,  2.1522],\n",
      "        [-0.4810, -0.4936, -0.3732,  2.1480, -0.4184, -0.5070, -0.5077, -0.4677,\n",
      "         -0.3228, -0.5019,  0.0510,  4.2507],\n",
      "        [-0.4810, -0.4832, -0.3833,  2.1369, -0.3473, -0.5052, -0.5077, -0.4716,\n",
      "         -0.4378, -0.5040,  0.0851,  1.3374],\n",
      "        [-0.3471, -0.4926, -0.3726,  2.1480, -0.3864, -0.4453, -0.5077, -0.4663,\n",
      "         -0.3860, -0.5021,  0.1527,  3.9509],\n",
      "        [-0.4743, -0.4936, -0.3679,  2.1289, -0.3975, -0.5068, -0.5077, -0.4686,\n",
      "         -0.4503, -0.5053,  0.1393,  2.0534],\n",
      "        [-0.4743, -0.4727, -0.3726,  2.1480, -0.4422, -0.5075, -0.5077, -0.4685,\n",
      "         -0.4726, -0.5034, -0.1979,  0.9903],\n",
      "        [-0.4676, -0.4893, -0.3886,  2.1119, -0.4167, -0.5068, -0.5077, -0.4694,\n",
      "         -0.4410, -0.5025, -0.0715,  2.3859],\n",
      "        [-0.4810, -0.4764, -0.3672,  2.0140, -0.4086, -0.5032, -0.5077, -0.4688,\n",
      "         -0.4546, -0.5030,  0.0965,  1.5476],\n",
      "        [-0.4676, -0.4588, -0.3967,  2.1480, -0.4569, -0.5074, -0.1564, -0.4655,\n",
      "         -0.4719, -0.5062, -0.2026,  1.4581],\n",
      "        [-0.4743, -0.4755, -0.3726,  2.1480, -0.4426, -0.5074, -0.5077, -0.4677,\n",
      "         -0.4713, -0.5045, -0.2040,  0.9968]]), tensor([[-0.3083],\n",
      "        [-0.3732],\n",
      "        [-0.3786],\n",
      "        [-0.4134],\n",
      "        [-0.3773],\n",
      "        [-0.3773],\n",
      "        [-0.3786],\n",
      "        [-0.3967],\n",
      "        [-0.3585],\n",
      "        [-0.3806]])]\n",
      "i_batch: 2\t-----batched_sample: [tensor([[-0.4810, -0.4716, -0.3806,  2.1480, -0.4723, -0.5075, -0.3405, -0.4627,\n",
      "         -0.4736, -0.5051, -0.2836,  1.3726],\n",
      "        [-0.4810, -0.4643, -0.3813,  2.1434, -0.4535, -0.5073, -0.4241, -0.4684,\n",
      "         -0.4673, -0.5059, -0.3645,  1.8013],\n",
      "        [-0.4877, -0.4460, -0.3833,  2.1235, -0.4539, -0.5076, -0.3906, -0.4602,\n",
      "         -0.4994, -0.5043, -0.1096,  0.9329],\n",
      "        [-0.4542, -0.4852, -0.3913,  2.0182, -0.4815, -0.5057, -0.5077, -0.4563,\n",
      "         -0.4658, -0.5044, -0.3940,  1.5445],\n",
      "        [-0.4810, -0.4810, -0.3846,  2.1435, -0.4226, -0.5046, -0.5077, -0.4668,\n",
      "         -0.4411, -0.5034, -0.1143,  1.5228],\n",
      "        [-0.3471, -0.4983, -0.3726,  2.1480, -0.3926,  0.0876, -0.5077, -0.4611,\n",
      "         -0.3870, -0.5025,  0.1072,  3.9502],\n",
      "        [-0.4810, -0.4836, -0.3846,  2.1399, -0.4456, -0.5053, -0.5077, -0.4638,\n",
      "         -0.4406, -0.5056,  0.0764,  1.5261],\n",
      "        [-0.4676, -0.4917, -0.3793,  2.1404, -0.4067, -0.5065, -0.5077, -0.4705,\n",
      "         -0.4434, -0.5038, -0.0159,  2.1058],\n",
      "        [-0.4676, -0.4910, -0.3793,  2.1480, -0.4118, -0.5062, -0.5077, -0.4674,\n",
      "         -0.4431, -0.5036,  0.0256,  2.1144],\n",
      "        [-0.4743, -0.4554, -0.4087,  1.9562, -0.4745, -0.5073, -0.0394, -0.4653,\n",
      "         -0.4928, -0.5053, -0.3732,  1.8914]]), tensor([[-0.3204],\n",
      "        [-0.3605],\n",
      "        [-0.2869],\n",
      "        [-0.1953],\n",
      "        [-0.3672],\n",
      "        [-0.4381],\n",
      "        [-0.3485],\n",
      "        [-0.3906],\n",
      "        [-0.3953],\n",
      "        [-0.3572]])]\n",
      "i_batch: 3\t-----batched_sample: [tensor([[-0.5010, -0.4910, -0.3672,  2.1480, -0.4550, -0.5074, -0.5077, -0.4674,\n",
      "         -0.4274, -0.5036,  0.0329,  1.3231],\n",
      "        [-0.4743, -0.4679, -0.4060,  2.1480, -0.3796, -0.5068, -0.4241, -0.4664,\n",
      "         -0.4552, -0.5042,  0.1353,  1.5787],\n",
      "        [-0.3471, -0.4930, -0.3726,  2.0919, -0.3977, -0.4413, -0.5077, -0.4659,\n",
      "         -0.3865, -0.5031,  0.1386,  3.9455],\n",
      "        [-0.3471, -0.4939, -0.3726,  2.0748, -0.3771, -0.4427, -0.5077, -0.4649,\n",
      "         -0.3878, -0.5021,  0.1426,  3.9455],\n",
      "        [-0.4810, -0.4813, -0.3833,  2.0738, -0.4450, -0.5068, -0.5077, -0.4651,\n",
      "         -0.4357, -0.5038, -0.2916,  1.3454],\n",
      "        [-0.4810, -0.4735, -0.4094,  2.1055, -0.4885, -0.5076,  0.1279, -0.4540,\n",
      "         -0.4890, -0.5060, -0.2943,  0.9939],\n",
      "        [-0.4810, -0.4809, -0.3672,  2.1188, -0.4152, -0.5020, -0.5077, -0.4678,\n",
      "         -0.4526, -0.5043,  0.0891,  1.5495],\n",
      "        [-0.4743, -0.4851, -0.3793,  2.0186, -0.4314, -0.5071, -0.5077, -0.4687,\n",
      "         -0.4689, -0.5051, -0.0969,  1.3543],\n",
      "        [-0.4944, -0.4870, -0.3886,  2.1256, -0.4529, -0.5075, -0.5077, -0.4649,\n",
      "         -0.4848, -0.5052, -0.0133,  1.3017],\n",
      "        [-0.4810, -0.4794, -0.3672,  2.0364, -0.4276, -0.5010, -0.5077, -0.4631,\n",
      "         -0.4541, -0.5048,  0.0764,  1.5412]]), tensor([[-0.4281],\n",
      "        [-0.3264],\n",
      "        [-0.4234],\n",
      "        [-0.3933],\n",
      "        [-0.3197],\n",
      "        [-0.1732],\n",
      "        [-0.3766],\n",
      "        [-0.3739],\n",
      "        [-0.3605],\n",
      "        [-0.3672]])]\n",
      "i_batch: 4\t-----batched_sample: [tensor([[-0.4810, -0.4776, -0.3672,  2.0807, -0.4637, -0.5007, -0.5077, -0.4680,\n",
      "         -0.4545, -0.5049, -0.3117,  1.5487],\n",
      "        [-0.4676, -0.4653, -0.3967,  2.1102, -0.4316, -0.5070, -0.3070, -0.4616,\n",
      "         -0.4745, -0.5044, -0.1444,  1.5023],\n",
      "        [-0.3471, -0.4939, -0.3726, -0.4833, -0.3929, -0.4489, -0.5077, -0.4705,\n",
      "         -0.3869, -0.5055, -0.0353,  3.9464],\n",
      "        [-0.4810, -0.4776, -0.3672,  2.1394, -0.4511, -0.5035, -0.5077, -0.4687,\n",
      "         -0.4542, -0.5019, -0.1297,  1.5428],\n",
      "        [-0.4609, -0.4481, -0.3799,  2.1480, -0.4840, -0.5053, -0.3605, -0.4525,\n",
      "         -0.4690, -0.5061, -0.4515,  1.7031],\n",
      "        [-0.4743, -0.4806, -0.3826,  1.9925, -0.4276, -0.5071, -0.5077, -0.4657,\n",
      "         -0.4203, -0.5039, -0.0092,  2.1533],\n",
      "        [-0.4743, -0.4907, -0.3679,  2.1101, -0.4037, -0.5060, -0.5077, -0.4661,\n",
      "         -0.4497, -0.5045,  0.1025,  2.0611],\n",
      "        [-0.3471, -0.4919, -0.3726,  2.0690, -0.3922, -0.4737, -0.5077, -0.4656,\n",
      "         -0.3870, -0.5048,  0.1065,  3.9531],\n",
      "        [-0.4810, -0.4635, -0.4000,  2.1480, -0.4765, -0.5075,  0.0276, -0.4656,\n",
      "         -0.4853, -0.5060, -0.3886,  1.7401],\n",
      "        [-0.4743, -0.4904, -0.3967,  2.1480, -0.4094, -0.5068, -0.5077, -0.4705,\n",
      "         -0.4802, -0.5033,  0.0844,  1.4708]]), tensor([[-0.3532],\n",
      "        [-0.3605],\n",
      "        [-0.4294],\n",
      "        [-0.3746],\n",
      "        [-0.2214],\n",
      "        [-0.3739],\n",
      "        [-0.3779],\n",
      "        [-0.4000],\n",
      "        [-0.3505],\n",
      "        [-0.3532]])]\n",
      "i_batch: 5\t-----batched_sample: [tensor([[-0.3471, -0.4967, -0.3726,  0.3445, -0.3295, -0.3342, -0.5077, -0.4722,\n",
      "         -0.3864, -0.5044,  0.0884,  3.9489],\n",
      "        [-0.3471, -0.4970, -0.3726,  1.6967, -0.3245, -0.2299, -0.5077, -0.4707,\n",
      "         -0.3858, -0.5035,  0.0637,  3.9492],\n",
      "        [-0.4810, -0.4794, -0.3833,  2.0437, -0.4096, -0.5068, -0.5077, -0.4672,\n",
      "         -0.4375, -0.5047, -0.1123,  1.3482],\n",
      "        [-0.4743, -0.4820, -0.3793,  2.1248, -0.4400, -0.5066, -0.5077, -0.4678,\n",
      "         -0.4678, -0.5042, -0.3057,  1.3571],\n",
      "        [-0.4542, -0.4594, -0.3759,  2.1480, -0.4627, -0.5070, -0.3405, -0.4645,\n",
      "         -0.4727, -0.5052, -0.0541,  1.3931],\n",
      "        [-0.3471, -0.4983, -0.3726, -0.4903, -0.4401, -0.1656, -0.5077, -0.4692,\n",
      "         -0.3864, -0.5035,  0.1614,  3.9511],\n",
      "        [-0.4810, -0.4643, -0.3813,  2.1480, -0.4489, -0.5069, -0.4241, -0.4684,\n",
      "         -0.4666, -0.5054, -0.2869,  1.7969],\n",
      "        [-0.4743, -0.4980, -0.4094,  2.1133, -0.3101, -0.4919, -0.5077, -0.4748,\n",
      "         -0.3770, -0.5026,  0.1326,  2.1888],\n",
      "        [-0.3471, -0.4854, -0.3726,  2.1224, -0.4559, -0.4695, -0.5077, -0.4626,\n",
      "         -0.3857, -0.5052, -0.0066,  3.9481],\n",
      "        [-0.4743, -0.4941, -0.4094,  2.0992, -0.4949, -0.4955, -0.5077, -0.4555,\n",
      "         -0.3772, -0.5037,  0.1493,  2.1868]]), tensor([[-0.4381],\n",
      "        [-0.4509],\n",
      "        [-0.3445],\n",
      "        [-0.3425],\n",
      "        [-0.3592],\n",
      "        [-0.4074],\n",
      "        [-0.3679],\n",
      "        [-0.4100],\n",
      "        [-0.3492],\n",
      "        [-0.1732]])]\n",
      "i_batch: 6\t-----batched_sample: [tensor([[-0.3471, -0.4976, -0.3726,  0.3716, -0.4185, -0.4173, -0.5077, -0.4819,\n",
      "         -0.3869, -0.5030,  0.1614,  3.9480],\n",
      "        [-0.4810, -0.4823, -0.3672,  2.1082, -0.4323, -0.5029, -0.5077, -0.4694,\n",
      "         -0.4533, -0.5039, -0.0427,  1.5426],\n",
      "        [-0.4877, -0.4695, -0.3880,  2.1317, -0.4580, -0.5067, -0.5077, -0.4662,\n",
      "         -0.4635, -0.5041, -0.4642,  1.0541],\n",
      "        [-0.3471, -0.4958, -0.3726,  2.1480, -0.3983, -0.4183, -0.5077, -0.4683,\n",
      "         -0.3861, -0.5028,  0.1259,  3.9506],\n",
      "        [-0.4743, -0.4970, -0.4094,  1.7892, -0.4266, -0.5002, -0.5077, -0.4742,\n",
      "         -0.3757, -0.5008,  0.0811,  2.1875],\n",
      "        [-0.4542, -0.4884, -0.3913,  2.0687, -0.4800, -0.5056, -0.5077, -0.4524,\n",
      "         -0.4667, -0.5052,  0.0162,  1.5485],\n",
      "        [-0.3471, -0.4979, -0.3726,  0.6924, -0.3754, -0.4111, -0.5077, -0.4619,\n",
      "         -0.3859, -0.5042,  0.1614,  3.9524],\n",
      "        [-0.4810, -0.4794, -0.3672,  1.9022, -0.3565, -0.5002, -0.5077, -0.4695,\n",
      "         -0.4532, -0.5030,  0.1219,  1.5474],\n",
      "        [-0.4743, -0.4897, -0.3967,  2.1234, -0.4432, -0.5072, -0.5077, -0.4685,\n",
      "         -0.4801, -0.5038, -0.0481,  1.4759],\n",
      "        [-0.4743, -0.4969, -0.4094,  1.2450, -0.4021, -0.4934, -0.5077, -0.4695,\n",
      "         -0.3775, -0.5000,  0.1513,  2.1875]]), tensor([[-0.3532],\n",
      "        [-0.3860],\n",
      "        [-0.3425],\n",
      "        [-0.4228],\n",
      "        [-0.4054],\n",
      "        [-0.2080],\n",
      "        [-0.3237],\n",
      "        [-0.4228],\n",
      "        [-0.3565],\n",
      "        [-0.3779]])]\n",
      "i_batch: 7\t-----batched_sample: [tensor([[-0.4944, -0.4843, -0.3873,  2.1141, -0.4319, -0.5070, -0.5077, -0.4665,\n",
      "         -0.4879, -0.5052, -0.0420,  1.3394],\n",
      "        [-0.4609, -0.4545, -0.3799,  2.0960, -0.3842, -0.5065, -0.3605, -0.4702,\n",
      "         -0.4706, -0.5048, -0.0380,  1.7038],\n",
      "        [-0.4877, -0.4781, -0.3833,  2.0928, -0.4207, -0.5057, -0.3739, -0.4686,\n",
      "         -0.4604, -0.5038, -0.2260,  0.9852],\n",
      "        [-0.3471, -0.4950, -0.3726,  1.8545, -0.4098, -0.4795, -0.5077, -0.4689,\n",
      "         -0.3881, -0.5024,  0.0878,  3.9522],\n",
      "        [-0.4944, -0.4658, -0.4094,  2.1270, -0.4580, -0.5075,  0.0443, -0.4665,\n",
      "         -0.4938, -0.5047, -0.2508,  1.8255],\n",
      "        [-0.4944, -0.4588, -0.4234,  1.8630, -0.4501, -0.5074,  0.0276, -0.4602,\n",
      "         -0.4971, -0.5041, -0.2628,  1.6949],\n",
      "        [-0.5010, -0.4460, -0.3980,  2.1365, -0.4458, -0.5075,  0.0276, -0.4684,\n",
      "         -0.4827, -0.5050, -0.3799,  1.5966],\n",
      "        [-0.4877, -0.4672, -0.3826,  2.1294, -0.4729, -0.5075, -0.5077, -0.4647,\n",
      "         -0.4925, -0.5048, -0.1150,  0.9804],\n",
      "        [-0.4743, -0.4726, -0.4080,  2.1167, -0.4770, -0.5075, -0.3739, -0.4611,\n",
      "         -0.4858, -0.5044, -0.2588,  0.9393],\n",
      "        [-0.4542, -0.4614, -0.3759,  2.1480, -0.4460, -0.5070, -0.3405, -0.4681,\n",
      "         -0.4743, -0.5022, -0.1919,  1.3881]]), tensor([[-0.3645],\n",
      "        [-0.3839],\n",
      "        [-0.3666],\n",
      "        [-0.3953],\n",
      "        [-0.3465],\n",
      "        [-0.3050],\n",
      "        [-0.3679],\n",
      "        [-0.3157],\n",
      "        [-0.2709],\n",
      "        [-0.3766]])]\n",
      "i_batch: 8\t-----batched_sample: [tensor([[-0.4810, -0.4800, -0.3900,  2.1480, -0.4596, -0.5072, -0.2401, -0.4644,\n",
      "         -0.4654, -0.5055, -0.2929,  1.1900],\n",
      "        [-0.3471, -0.4962, -0.3726,  2.1480, -0.3682, -0.4532, -0.5077, -0.4717,\n",
      "         -0.3865, -0.5034,  0.1540,  3.9461],\n",
      "        [-0.4810, -0.4956, -0.3732,  2.1359, -0.3869, -0.5067, -0.5077, -0.4712,\n",
      "         -0.3227, -0.5038,  0.1125,  4.2421],\n",
      "        [-0.3471, -0.4872, -0.3726,  1.7298, -0.4132, -0.4866, -0.5077, -0.4692,\n",
      "         -0.3866, -0.5044, -0.1852,  3.9439],\n",
      "        [-0.5010, -0.4684, -0.4167,  2.1388, -0.4866, -0.5076,  0.0945, -0.4547,\n",
      "         -0.4994, -0.5062, -0.3418,  0.8156],\n",
      "        [-0.3471, -0.4894, -0.3726,  2.1480, -0.4141, -0.4632, -0.5077, -0.4655,\n",
      "         -0.3856, -0.5034,  0.0476,  3.9476],\n",
      "        [-0.4877, -0.4780, -0.3839,  2.1172, -0.4640, -0.5074, -0.5077, -0.4634,\n",
      "         -0.4782, -0.5053, -0.1324,  1.1398],\n",
      "        [-0.4542, -0.4862, -0.3913,  1.9819, -0.4652, -0.5050, -0.5077, -0.4598,\n",
      "         -0.4663, -0.5044,  0.0269,  1.5475],\n",
      "        [-0.4743, -0.4761, -0.3766,  2.1094, -0.4292, -0.5058, -0.5077, -0.4695,\n",
      "         -0.4578, -0.5042, -0.0106,  1.4133],\n",
      "        [-0.4743, -0.4982, -0.4094,  0.6492, -0.3217, -0.4918, -0.5077, -0.4667,\n",
      "         -0.3769, -0.5013,  0.1614,  2.1931]]), tensor([[-0.3130],\n",
      "        [-0.4308],\n",
      "        [-0.4060],\n",
      "        [-0.3746],\n",
      "        [-0.1732],\n",
      "        [-0.3773],\n",
      "        [-0.3297],\n",
      "        [-0.2963],\n",
      "        [-0.3839],\n",
      "        [-0.4154]])]\n",
      "i_batch: 9\t-----batched_sample: [tensor([[-0.4944, -0.4943, -0.3799,  2.0308, -0.3901, -0.5071, -0.5077, -0.4684,\n",
      "         -0.3384, -0.5035,  0.1333,  0.7506],\n",
      "        [-0.3471, -0.4979, -0.3726,  2.1480, -0.3185, -0.3445, -0.5077, -0.4766,\n",
      "         -0.3871, -0.5030,  0.1614,  3.9486],\n",
      "        [-0.4743, -0.4705, -0.4060,  2.1393, -0.4246, -0.5071, -0.4241, -0.4675,\n",
      "         -0.4549, -0.5045, -0.0621,  1.5779],\n",
      "        [-0.4542, -0.4594, -0.3759,  2.1360, -0.4197, -0.5067, -0.3405, -0.4693,\n",
      "         -0.4738, -0.5057, -0.0648,  1.3917],\n",
      "        [-0.4743, -0.4670, -0.4060,  2.0793, -0.3075, -0.5063, -0.4241, -0.4701,\n",
      "         -0.4554, -0.5044,  0.1614,  1.5751],\n",
      "        [-0.5010, -0.4489, -0.3759,  2.1480, -0.4677, -0.5073, -0.2401, -0.4643,\n",
      "         -0.4994, -0.5055, -0.2106,  1.7368],\n",
      "        [-0.4810, -0.4946, -0.3659,  2.0232, -0.3947, -0.5056, -0.5077, -0.4680,\n",
      "         -0.3606, -0.5032,  0.1179,  2.4069],\n",
      "        [-0.3471, -0.4910, -0.3726, -0.4630, -0.3825, -0.4441, -0.5077, -0.4627,\n",
      "         -0.3876, -0.5048,  0.1219,  3.9481],\n",
      "        [-0.3471, -0.5001, -0.3726,  2.1480, -0.2537, -0.3840, -0.5077, -0.4800,\n",
      "         -0.3860, -0.5037,  0.1614,  3.9525],\n",
      "        [-0.4743, -0.4918, -0.4094,  1.8217, -0.4272, -0.4923, -0.5077, -0.4684,\n",
      "         -0.3776, -0.5043,  0.1433,  2.1904]]), tensor([[-0.3819],\n",
      "        [-0.4375],\n",
      "        [-0.3545],\n",
      "        [-0.3826],\n",
      "        [-0.3973],\n",
      "        [-0.3545],\n",
      "        [-0.3913],\n",
      "        [-0.4080],\n",
      "        [-0.4154],\n",
      "        [-0.3799]])]\n",
      "i_batch: 10\t-----batched_sample: [tensor([[-0.4810, -0.4762, -0.3672,  2.1480, -0.4525, -0.5035, -0.5077, -0.4679,\n",
      "         -0.4537, -0.5050, -0.0942,  1.5515],\n",
      "        [-0.4810, -0.4855, -0.3846,  2.1480, -0.4774, -0.5044, -0.5077, -0.4633,\n",
      "         -0.4395, -0.5053,  0.0443,  1.5291],\n",
      "        [-0.4810, -0.4779, -0.3672,  2.0880, -0.4221, -0.5026, -0.5077, -0.4643,\n",
      "         -0.4518, -0.5045,  0.1239,  1.5503],\n",
      "        [-0.4810, -0.4813, -0.3833,  2.1480, -0.4350, -0.5068, -0.5077, -0.4683,\n",
      "         -0.4357, -0.5065, -0.3585,  1.3512],\n",
      "        [-0.4743, -0.4976, -0.4094,  0.6249, -0.3963, -0.4933, -0.5077, -0.4701,\n",
      "         -0.3771, -0.5025,  0.1614,  2.1862],\n",
      "        [-0.3471, -0.4952, -0.3726,  2.1115, -0.3598, -0.3602, -0.5077, -0.4688,\n",
      "         -0.3864, -0.5023,  0.1105,  3.9444],\n",
      "        [-0.3471, -0.4913, -0.3726,  2.0073, -0.3957, -0.4525, -0.5077, -0.4583,\n",
      "         -0.3863, -0.5038,  0.1567,  3.9512],\n",
      "        [-0.4944, -0.4463, -0.3920,  2.1480, -0.4691, -0.5076,  0.0610, -0.4650,\n",
      "         -0.5025, -0.5055, -0.2689,  1.5862],\n",
      "        [-0.4542, -0.4800, -0.3913,  2.0915, -0.4439, -0.5043, -0.5077, -0.4634,\n",
      "         -0.4646, -0.5036,  0.0041,  1.5455],\n",
      "        [-0.4810, -0.4792, -0.3672,  2.0801, -0.4096, -0.5025, -0.5077, -0.4677,\n",
      "         -0.4516, -0.5050,  0.0389,  1.5437]]), tensor([[-0.3712],\n",
      "        [-0.3552],\n",
      "        [-0.3846],\n",
      "        [-0.3565],\n",
      "        [-0.4034],\n",
      "        [-0.4375],\n",
      "        [-0.3886],\n",
      "        [-0.3425],\n",
      "        [-0.3398],\n",
      "        [-0.3906]])]\n",
      "i_batch: 11\t-----batched_sample: [tensor([[-0.4877, -0.4781, -0.3833,  2.1480, -0.4636, -0.5066, -0.3739, -0.4660,\n",
      "         -0.4617, -0.5042, -0.3987,  0.9855],\n",
      "        [-0.4810, -0.4909, -0.3846,  1.8372, -0.4232, -0.4901, -0.5077, -0.4745,\n",
      "         -0.4414, -0.5055, -0.2548,  1.5264],\n",
      "        [-0.3471, -0.4972, -0.3726,  2.1480, -0.3498, -0.4463, -0.5077, -0.4707,\n",
      "         -0.3870, -0.5026,  0.1614,  3.9528],\n",
      "        [-0.4743, -0.4940, -0.4094,  1.9633, -0.4830, -0.4943, -0.5077, -0.4547,\n",
      "         -0.3767, -0.5053,  0.1360,  2.1919],\n",
      "        [-0.4743, -0.4896, -0.3679,  2.1317, -0.4178, -0.5063, -0.5077, -0.4667,\n",
      "         -0.4496, -0.5030,  0.0771,  2.0644],\n",
      "        [-0.3471, -0.4978, -0.3726,  2.1480, -0.3031, -0.2511, -0.5077, -0.4712,\n",
      "         -0.3866, -0.5027,  0.1614,  3.9469],\n",
      "        [-0.4810, -0.4823, -0.3672,  1.4259, -0.4295, -0.5024, -0.5077, -0.4712,\n",
      "         -0.4532, -0.5051, -0.2628,  1.5404],\n",
      "        [-0.3471, -0.4999, -0.3726,  1.9695, -0.3516, -0.3691, -0.5077, -0.4800,\n",
      "         -0.3871, -0.5041,  0.1614,  3.9506],\n",
      "        [-0.4877, -0.4695, -0.3880,  2.0711, -0.4753, -0.5069, -0.5077, -0.4624,\n",
      "         -0.4615, -0.5065, -0.4883,  1.0533],\n",
      "        [-0.3471, -0.4944, -0.3726, -0.2196, -0.3473, -0.4363, -0.5077, -0.4645,\n",
      "         -0.3861, -0.5037,  0.1266,  3.9524]]), tensor([[-0.3391],\n",
      "        [-0.4000],\n",
      "        [-0.4321],\n",
      "        [-0.1732],\n",
      "        [-0.3786],\n",
      "        [-0.4743],\n",
      "        [-0.3726],\n",
      "        [-0.4281],\n",
      "        [-0.3297],\n",
      "        [-0.4288]])]\n",
      "i_batch: 12\t-----batched_sample: [tensor([[-0.4810, -0.4859, -0.3846,  2.1245, -0.4549, -0.5059, -0.5077, -0.4658,\n",
      "         -0.4425, -0.5023,  0.0463,  1.5277],\n",
      "        [-0.4743, -0.4793, -0.3826,  2.1347, -0.4624, -0.5072, -0.5077, -0.4658,\n",
      "         -0.4228, -0.5068, -0.4676,  2.1529],\n",
      "        [-0.5010, -0.4588, -0.4054,  2.1334, -0.4552, -0.5077,  0.0945, -0.4603,\n",
      "         -0.4855, -0.5061, -0.3686,  1.4008],\n",
      "        [-0.3471, -0.4956, -0.3726, -0.3634, -0.3352, -0.4352, -0.5077, -0.4624,\n",
      "         -0.3861, -0.5032,  0.0998,  3.9485],\n",
      "        [-0.4877, -0.4815, -0.3833,  2.1108, -0.4164, -0.5071, -0.3739, -0.4681,\n",
      "         -0.4607, -0.5050, -0.0962,  0.9882],\n",
      "        [-0.3471, -0.4883, -0.3726,  1.9596, -0.3864, -0.4035, -0.5077, -0.4681,\n",
      "         -0.3861, -0.5041, -0.0327,  3.9493],\n",
      "        [-0.5010, -0.4917, -0.3672,  2.1249, -0.4644, -0.5070, -0.5077, -0.4623,\n",
      "         -0.4290, -0.5032,  0.0898,  1.3251],\n",
      "        [-0.4609, -0.4582, -0.3799,  2.0153, -0.4837, -0.5063, -0.3605, -0.4647,\n",
      "         -0.4674, -0.5040, -0.4482,  1.7042],\n",
      "        [-0.3471, -0.4999, -0.3726,  2.1480, -0.2751, -0.4334, -0.5077, -0.4749,\n",
      "         -0.3862, -0.5052,  0.1614,  3.9485],\n",
      "        [-0.4877, -0.4565, -0.3940,  2.0637, -0.4780, -0.5076,  0.1279, -0.4600,\n",
      "         -0.4976, -0.5049, -0.4147,  2.1811]]), tensor([[-0.3632],\n",
      "        [-0.3465],\n",
      "        [-0.2923],\n",
      "        [-0.4576],\n",
      "        [-0.3692],\n",
      "        [-0.3799],\n",
      "        [-0.3605],\n",
      "        [-0.3418],\n",
      "        [-0.4154],\n",
      "        [-0.2876]])]\n",
      "i_batch: 13\t-----batched_sample: [tensor([[-0.4743, -0.4645, -0.3726,  2.0978, -0.4626, -0.5075, -0.5077, -0.4655,\n",
      "         -0.4742, -0.5051, -0.2501,  0.9933],\n",
      "        [-0.4944, -0.4930, -0.3799,  2.0193, -0.4123, -0.5073, -0.5077, -0.4676,\n",
      "         -0.3366, -0.5058,  0.0550,  0.7470],\n",
      "        [-0.4676, -0.4607, -0.3967,  1.9864, -0.4327, -0.5070, -0.3070, -0.4652,\n",
      "         -0.4750, -0.5054, -0.1538,  1.5026],\n",
      "        [-0.4743, -0.4989, -0.4094,  2.1480, -0.3283, -0.4855, -0.5077, -0.4716,\n",
      "         -0.3767, -0.5004,  0.1614,  2.1877],\n",
      "        [-0.4676, -0.4918, -0.3793,  2.1480, -0.4168, -0.5059, -0.5077, -0.4681,\n",
      "         -0.4421, -0.5042, -0.2227,  2.1089],\n",
      "        [-0.4810, -0.4757, -0.3900,  2.0968, -0.4673, -0.5070, -0.2401, -0.4591,\n",
      "         -0.4641, -0.5057, -0.1799,  1.1887],\n",
      "        [-0.3471, -0.4910, -0.3726,  2.1108, -0.4189, -0.4820, -0.5077, -0.4649,\n",
      "         -0.3868, -0.5031,  0.1012,  3.9500],\n",
      "        [-0.4810, -0.4621, -0.3953,  2.1284, -0.4446, -0.5074, -0.3672, -0.4668,\n",
      "         -0.4691, -0.5038, -0.0862,  1.1189],\n",
      "        [-0.4609, -0.4582, -0.3799,  2.1438, -0.4683, -0.5068, -0.3605, -0.4643,\n",
      "         -0.4669, -0.5056, -0.4207,  1.6997],\n",
      "        [-0.4944, -0.4843, -0.3873,  2.1480, -0.4663, -0.5073, -0.5077, -0.4581,\n",
      "         -0.4889, -0.5050, -0.0895,  1.3392]]), tensor([[-0.3692],\n",
      "        [-0.3719],\n",
      "        [-0.3592],\n",
      "        [-0.4181],\n",
      "        [-0.3438],\n",
      "        [-0.2856],\n",
      "        [-0.3625],\n",
      "        [-0.3706],\n",
      "        [-0.3445],\n",
      "        [-0.2856]])]\n",
      "i_batch: 14\t-----batched_sample: [tensor([[-0.4877, -0.4736, -0.3880,  2.1480, -0.4131, -0.5065, -0.5077, -0.4690,\n",
      "         -0.4623, -0.5057, -0.2849,  1.0498],\n",
      "        [-0.3471, -0.4937, -0.3726,  2.0402, -0.4396, -0.4831, -0.5077, -0.4719,\n",
      "         -0.3864, -0.5009,  0.1360,  3.9498],\n",
      "        [-0.5010, -0.4661, -0.4034,  2.0128, -0.4784, -0.5076, -0.1063, -0.4635,\n",
      "         -0.4878, -0.5045, -0.3819,  1.2637],\n",
      "        [-0.4676, -0.4663, -0.3967,  2.0602, -0.4584, -0.5071, -0.3070, -0.4635,\n",
      "         -0.4741, -0.5046, -0.2254,  1.5068],\n",
      "        [-0.4743, -0.4924, -0.4207,  2.0808, -0.4682, -0.5043, -0.3739, -0.4515,\n",
      "         -0.4820, -0.5025,  0.1045,  1.2553],\n",
      "        [-0.4743, -0.4644, -0.4060,  2.0999, -0.4764, -0.5073, -0.2066, -0.4626,\n",
      "         -0.4861, -0.5036, -0.3016,  2.1534],\n",
      "        [-0.3471, -0.4991, -0.3726,  1.7143, -0.4266, -0.4278, -0.5077, -0.4702,\n",
      "         -0.3857, -0.5020,  0.1614,  3.9543],\n",
      "        [-0.4877, -0.4758, -0.3839,  2.1480, -0.4434, -0.5074, -0.5077, -0.4650,\n",
      "         -0.4782, -0.5041, -0.1866,  1.1442],\n",
      "        [-0.4810, -0.4621, -0.3953,  2.1480, -0.4724, -0.5074, -0.3672, -0.4642,\n",
      "         -0.4700, -0.5061, -0.3666,  1.1160],\n",
      "        [-0.4743, -0.4937, -0.4094,  1.4801, -0.4335, -0.4923, -0.5077, -0.4655,\n",
      "         -0.3761, -0.5039,  0.1353,  2.1920]]), tensor([[-0.3739],\n",
      "        [-0.3686],\n",
      "        [-0.3130],\n",
      "        [-0.3518],\n",
      "        [-0.1812],\n",
      "        [-0.3037],\n",
      "        [-0.3211],\n",
      "        [-0.3478],\n",
      "        [-0.3405],\n",
      "        [-0.3485]])]\n",
      "i_batch: 15\t-----batched_sample: [tensor([[-0.3471, -0.4914, -0.3726, -0.1670, -0.3864, -0.4759, -0.5077, -0.4641,\n",
      "         -0.3872, -0.5017,  0.0711,  3.9497],\n",
      "        [-0.4877, -0.4588, -0.3666,  2.1480, -0.4087, -0.5076, -0.0059, -0.4683,\n",
      "         -0.4823, -0.5050, -0.1892,  2.6254],\n",
      "        [-0.3471, -0.4960, -0.3726,  1.6069, -0.4141, -0.4830, -0.5077, -0.4745,\n",
      "         -0.3873, -0.5034,  0.1038,  3.9426],\n",
      "        [-0.4743, -0.4661, -0.4060,  2.1480, -0.4189, -0.5069, -0.4241, -0.4675,\n",
      "         -0.4539, -0.5040,  0.0470,  1.5661],\n",
      "        [-0.3471, -0.4957, -0.3726, -0.1835, -0.3556, -0.4287, -0.5077, -0.4621,\n",
      "         -0.3859, -0.5039,  0.0041,  3.9505],\n",
      "        [-0.3471, -0.4849, -0.3726,  2.1372, -0.4608, -0.4694, -0.5077, -0.4605,\n",
      "         -0.3856, -0.5026,  0.0075,  3.9466],\n",
      "        [-0.4877, -0.4697, -0.3880,  2.1202, -0.3819, -0.5062, -0.5077, -0.4674,\n",
      "         -0.4619, -0.5046,  0.0644,  1.0485],\n",
      "        [-0.4810, -0.4803, -0.3672,  2.1322, -0.3747, -0.5011, -0.5077, -0.4688,\n",
      "         -0.4522, -0.5039,  0.1614,  1.5474],\n",
      "        [-0.4810, -0.4966, -0.3659,  2.1480, -0.3842, -0.5041, -0.5077, -0.4666,\n",
      "         -0.3603, -0.5041,  0.1473,  2.4189],\n",
      "        [-0.4810, -0.4958, -0.3659,  2.1159, -0.3927, -0.5060, -0.5077, -0.4696,\n",
      "         -0.3608, -0.5025,  0.1346,  2.4130]]), tensor([[-0.4134],\n",
      "        [-0.3813],\n",
      "        [-0.3612],\n",
      "        [-0.3813],\n",
      "        [-0.4515],\n",
      "        [-0.3405],\n",
      "        [-0.3967],\n",
      "        [-0.4107],\n",
      "        [-0.3886],\n",
      "        [-0.3993]])]\n",
      "i_batch: 16\t-----batched_sample: [tensor([[-0.3471, -0.4950, -0.3726,  1.8646, -0.4723, -0.4845, -0.5077, -0.4490,\n",
      "         -0.3873, -0.5018,  0.0470,  3.9495],\n",
      "        [-0.4743, -0.4915, -0.4094,  1.0152, -0.4265, -0.4957, -0.5077, -0.4684,\n",
      "         -0.3768, -0.5046,  0.0222,  2.1953],\n",
      "        [-0.4743, -0.4935, -0.3679,  2.0864, -0.4135, -0.5069, -0.5077, -0.4667,\n",
      "         -0.4493, -0.5037,  0.0624,  2.0641],\n",
      "        [-0.4743, -0.4960, -0.4094,  1.6403, -0.4066, -0.4983, -0.5077, -0.4667,\n",
      "         -0.3761, -0.5014,  0.1346,  2.1789],\n",
      "        [-0.4944, -0.4944, -0.3799,  2.0685, -0.4086, -0.5066, -0.5077, -0.4677,\n",
      "         -0.3356, -0.5047,  0.0838,  0.7484],\n",
      "        [-0.4743, -0.4848, -0.3980,  2.1204, -0.4429, -0.5073, -0.5077, -0.4633,\n",
      "         -0.4154, -0.5041,  0.0617,  1.3397],\n",
      "        [-0.4743, -0.4952, -0.4094,  1.9240, -0.4770, -0.4995, -0.5077, -0.4613,\n",
      "         -0.3766, -0.5028,  0.1440,  2.1867],\n",
      "        [-0.3471, -0.4972, -0.3726,  2.1480, -0.3718, -0.4125, -0.5077, -0.4653,\n",
      "         -0.3870, -0.5027,  0.1614,  3.9457],\n",
      "        [-0.4743, -0.4653, -0.4060,  2.1187, -0.3709, -0.5062, -0.4241, -0.4651,\n",
      "         -0.4551, -0.5050,  0.1232,  1.5725],\n",
      "        [-0.3471, -0.4915, -0.3726,  1.8514, -0.3864, -0.4538, -0.5077, -0.4714,\n",
      "         -0.3856, -0.5050,  0.1306,  3.9516]]), tensor([[-0.3612],\n",
      "        [-0.3485],\n",
      "        [-0.3712],\n",
      "        [-0.3940],\n",
      "        [-0.3645],\n",
      "        [-0.3157],\n",
      "        [-0.2314],\n",
      "        [-0.4596],\n",
      "        [-0.4074],\n",
      "        [-0.4154]])]\n",
      "i_batch: 17\t-----batched_sample: [tensor([[-0.4877, -0.4695, -0.3880,  2.0977, -0.4438, -0.5069, -0.5077, -0.4671,\n",
      "         -0.4606, -0.5046, -0.2401,  1.0497],\n",
      "        [-0.4743, -0.4961, -0.4094,  0.0812, -0.4072, -0.4841, -0.5077, -0.4666,\n",
      "         -0.3776, -0.5005,  0.0450,  2.1863],\n",
      "        [-0.4810, -0.4519, -0.3940,  2.1081, -0.4677, -0.5076,  0.0276, -0.4633,\n",
      "         -0.4943, -0.5041, -0.3090,  1.3640],\n",
      "        [-0.4810, -0.4981, -0.3659,  2.1480, -0.2775, -0.4968, -0.5077, -0.4742,\n",
      "         -0.3622, -0.5023,  0.1614,  2.4114],\n",
      "        [-0.4743, -0.4742, -0.3826,  2.0777, -0.4252, -0.5074, -0.5077, -0.4660,\n",
      "         -0.4206, -0.5055, -0.1484,  2.1564],\n",
      "        [-0.3471, -0.4870, -0.3726,  2.1375, -0.4216, -0.4807, -0.5077, -0.4661,\n",
      "         -0.3874, -0.5036,  0.0992,  3.9474],\n",
      "        [-0.4877, -0.4670, -0.3880,  2.1480, -0.3993, -0.5063, -0.5077, -0.4703,\n",
      "         -0.4616, -0.5045, -0.0929,  1.0493],\n",
      "        [-0.4743, -0.4804, -0.3826,  2.0815, -0.4390, -0.5072, -0.5077, -0.4667,\n",
      "         -0.4228, -0.5060, -0.2013,  2.1552],\n",
      "        [-0.4743, -0.4951, -0.4207,  2.0569, -0.4556, -0.5033, -0.3739, -0.4587,\n",
      "         -0.4817, -0.5031,  0.1614,  1.2555],\n",
      "        [-0.3471, -0.4879, -0.3726,  2.1480, -0.4193, -0.4553, -0.5077, -0.4662,\n",
      "         -0.3860, -0.5032, -0.0701,  3.9477]]), tensor([[-0.3659],\n",
      "        [-0.4034],\n",
      "        [-0.3438],\n",
      "        [-0.4114],\n",
      "        [-0.3659],\n",
      "        [-0.3766],\n",
      "        [-0.3779],\n",
      "        [-0.3686],\n",
      "        [-0.2669],\n",
      "        [-0.3645]])]\n",
      "i_batch: 18\t-----batched_sample: [tensor([[-0.4743, -0.4774, -0.3766,  2.1480, -0.4596, -0.5066, -0.5077, -0.4647,\n",
      "         -0.4576, -0.5069, -0.1578,  1.4083],\n",
      "        [-0.4810, -0.4786, -0.3833,  2.0980, -0.3869, -0.5060, -0.5077, -0.4690,\n",
      "         -0.4374, -0.5049, -0.0213,  1.3414],\n",
      "        [-0.4743, -0.4933, -0.4094,  2.0915, -0.4855, -0.4976, -0.5077, -0.4517,\n",
      "         -0.3762, -0.5045,  0.1206,  2.1895],\n",
      "        [-0.4609, -0.4538, -0.3799,  2.1030, -0.4464, -0.5055, -0.3605, -0.4669,\n",
      "         -0.4684, -0.5051, -0.2742,  1.7005],\n",
      "        [-0.3471, -0.4980, -0.3726,  1.5976, -0.3311, -0.4582, -0.5077, -0.4701,\n",
      "         -0.3879, -0.5039,  0.1473,  3.9469],\n",
      "        [-0.3471, -0.4975, -0.3726,  2.1480, -0.3434, -0.4543, -0.5077, -0.4708,\n",
      "         -0.3875, -0.5030,  0.1614,  3.9451],\n",
      "        [-0.4743, -0.4925, -0.4094,  1.0992, -0.4421, -0.4882, -0.5077, -0.4669,\n",
      "         -0.3767, -0.5045,  0.1145,  2.1885],\n",
      "        [-0.4743, -0.4713, -0.4060,  2.1052, -0.4026, -0.5071, -0.4241, -0.4683,\n",
      "         -0.4542, -0.5048, -0.2468,  1.5723],\n",
      "        [-0.4810, -0.4912, -0.3659,  2.0931, -0.4072, -0.5055, -0.5077, -0.4688,\n",
      "         -0.3604, -0.5031,  0.1306,  2.4174],\n",
      "        [-0.4810, -0.4361, -0.3853,  1.9732, -0.4710, -0.5072, -0.1063, -0.4637,\n",
      "         -0.4959, -0.5049, -0.2675,  2.2435]]), tensor([[-0.3485],\n",
      "        [-0.3572],\n",
      "        [-0.1732],\n",
      "        [-0.3451],\n",
      "        [-0.3926],\n",
      "        [-0.4254],\n",
      "        [-0.3405],\n",
      "        [-0.3625],\n",
      "        [-0.3846],\n",
      "        [-0.3465]])]\n",
      "i_batch: 19\t-----batched_sample: [tensor([[-0.3471, -0.4971, -0.3726,  2.1480, -0.3286, -0.3401, -0.5077, -0.4677,\n",
      "         -0.3866, -0.5017,  0.1614,  3.9506],\n",
      "        [-0.4609, -0.4852, -0.3846,  2.1243, -0.4480, -0.5074, -0.2869, -0.4635,\n",
      "         -0.4946, -0.5039, -0.1190,  0.9754],\n",
      "        [-0.4743, -0.4915, -0.3679,  2.1369, -0.4256, -0.5069, -0.5077, -0.4644,\n",
      "         -0.4499, -0.5037,  0.1420,  2.0653],\n",
      "        [-0.4542, -0.4833, -0.3913,  1.9024, -0.4539, -0.5047, -0.5077, -0.4627,\n",
      "         -0.4658, -0.5038, -0.0628,  1.5416],\n",
      "        [-0.3471, -0.4957, -0.3726, -0.3977, -0.3698, -0.0157, -0.5077, -0.4679,\n",
      "         -0.3855, -0.5044,  0.1614,  3.9493],\n",
      "        [-0.3471, -0.4891, -0.3726, -0.4843, -0.3944, -0.4529, -0.5077, -0.4680,\n",
      "         -0.3868, -0.5032,  0.0296,  3.9482],\n",
      "        [-0.4877, -0.4858, -0.3886,  2.0825, -0.4197, -0.5073, -0.5077, -0.4666,\n",
      "         -0.4916, -0.5054, -0.0474,  0.7852],\n",
      "        [-0.4676, -0.4895, -0.3886,  2.1239, -0.4272, -0.5069, -0.5077, -0.4664,\n",
      "         -0.4411, -0.5041, -0.0226,  2.3824],\n",
      "        [-0.4676, -0.4607, -0.3967,  1.9995, -0.4730, -0.5069, -0.3070, -0.4650,\n",
      "         -0.4750, -0.5046, -0.4555,  1.5014],\n",
      "        [-0.4810, -0.4969, -0.3659,  2.0890, -0.3461, -0.5058, -0.5077, -0.4664,\n",
      "         -0.3612, -0.5035,  0.1186,  2.4124]]), tensor([[-0.4703],\n",
      "        [-0.3177],\n",
      "        [-0.3752],\n",
      "        [-0.3137],\n",
      "        [-0.4489],\n",
      "        [-0.4174],\n",
      "        [-0.3097],\n",
      "        [-0.3659],\n",
      "        [-0.3492],\n",
      "        [-0.4141]])]\n",
      "i_batch: 20\t-----batched_sample: [tensor([[-0.4676, -0.4884, -0.3793,  2.1480, -0.4134, -0.5059, -0.5077, -0.4690,\n",
      "         -0.4431, -0.5047, -0.0353,  2.1089],\n",
      "        [-0.4542, -0.4800, -0.3913,  2.1023, -0.4761, -0.5043, -0.5077, -0.4585,\n",
      "         -0.4662, -0.5031, -0.0286,  1.5452],\n",
      "        [-0.4609, -0.4554, -0.3799,  1.9995, -0.4440, -0.5066, -0.3605, -0.4647,\n",
      "         -0.4699, -0.5049, -0.1792,  1.6968],\n",
      "        [-0.4743, -0.4957, -0.4094,  1.7600, -0.4709, -0.4992, -0.5077, -0.4659,\n",
      "         -0.3770, -0.5038,  0.1119,  2.1883],\n",
      "        [-0.4877, -0.4815, -0.3833,  2.1350, -0.4560, -0.5070, -0.3739, -0.4640,\n",
      "         -0.4627, -0.5036, -0.1150,  0.9806],\n",
      "        [-0.3471, -0.4953, -0.3726, -0.3818, -0.4106, -0.2557, -0.5077, -0.4662,\n",
      "         -0.3867, -0.5026,  0.0189,  3.9487],\n",
      "        [-0.4944, -0.4745, -0.3886,  2.1208, -0.4808, -0.5076, -0.5077, -0.4597,\n",
      "         -0.4616, -0.5038, -0.0989,  1.1085],\n",
      "        [-0.4810, -0.4956, -0.3659,  2.1480, -0.4048, -0.5056, -0.5077, -0.4647,\n",
      "         -0.3608, -0.5035,  0.1534,  2.4146],\n",
      "        [-0.3471, -0.5002, -0.3726,  1.8200, -0.4483, -0.4524, -0.5077, -0.4684,\n",
      "         -0.3871, -0.5027,  0.0918,  3.9516],\n",
      "        [-0.4743, -0.4869, -0.3980,  2.1206, -0.4173, -0.5074, -0.5077, -0.4683,\n",
      "         -0.4162, -0.5040, -0.1330,  1.3367]]), tensor([[-0.3853],\n",
      "        [-0.2970],\n",
      "        [-0.3438],\n",
      "        [-0.3271],\n",
      "        [-0.3445],\n",
      "        [-0.4348],\n",
      "        [-0.2756],\n",
      "        [-0.3873],\n",
      "        [-0.1732],\n",
      "        [-0.3518]])]\n",
      "i_batch: 21\t-----batched_sample: [tensor([[-0.4944, -0.4658, -0.4094,  2.1378, -0.4869, -0.5076,  0.0443, -0.4568,\n",
      "         -0.4937, -0.5057, -0.4027,  1.8207],\n",
      "        [-0.4810, -0.4635, -0.4000,  2.1480, -0.4392, -0.5074,  0.0276, -0.4690,\n",
      "         -0.4873, -0.5052, -0.2996,  1.7484],\n",
      "        [-0.3471, -0.4888, -0.3726,  2.1480, -0.4090, -0.4202, -0.5077, -0.4695,\n",
      "         -0.3856, -0.5030, -0.1283,  3.9437],\n",
      "        [-0.4810, -0.4735, -0.3793,  2.1480, -0.4855, -0.5075,  0.0276, -0.4618,\n",
      "         -0.4753, -0.5051, -0.3211,  1.1309],\n",
      "        [-0.4542, -0.4832, -0.3913,  2.0239, -0.4298, -0.5041, -0.5077, -0.4677,\n",
      "         -0.4660, -0.5035, -0.0521,  1.5508],\n",
      "        [-0.4877, -0.4888, -0.3886,  2.1480, -0.4740, -0.5073, -0.5077, -0.4610,\n",
      "         -0.4906, -0.5051, -0.1170,  0.7894],\n",
      "        [-0.3471, -0.4931, -0.3726,  1.5278, -0.3785, -0.4574, -0.5077, -0.4648,\n",
      "         -0.3850, -0.5034,  0.1500,  3.9475],\n",
      "        [-0.4810, -0.4716, -0.3806,  2.1061, -0.4575, -0.5075, -0.3405, -0.4665,\n",
      "         -0.4752, -0.5066, -0.1953,  1.3712],\n",
      "        [-0.4676, -0.4918, -0.3793,  2.1480, -0.4274, -0.5066, -0.5077, -0.4695,\n",
      "         -0.4439, -0.5037, -0.1464,  2.1054],\n",
      "        [-0.4743, -0.4868, -0.3967,  2.1082, -0.4721, -0.5073, -0.5077, -0.4639,\n",
      "         -0.4812, -0.5033, -0.2863,  1.4722]]), tensor([[-0.2247],\n",
      "        [-0.3779],\n",
      "        [-0.3732],\n",
      "        [-0.3170],\n",
      "        [-0.3451],\n",
      "        [-0.2588],\n",
      "        [-0.4207],\n",
      "        [-0.3545],\n",
      "        [-0.3619],\n",
      "        [-0.3110]])]\n",
      "i_batch: 22\t-----batched_sample: [tensor([[-0.5010, -0.4661, -0.4034,  2.1244, -0.4741, -0.5076, -0.1063, -0.4622,\n",
      "         -0.4892, -0.5061, -0.4415,  1.2661],\n",
      "        [-0.4810, -0.4805, -0.3900,  2.1480, -0.4841, -0.5074, -0.2401, -0.4625,\n",
      "         -0.4638, -0.5042, -0.2876,  1.1887],\n",
      "        [-0.4743, -0.4969, -0.4094,  1.9867, -0.4134, -0.4966, -0.5077, -0.4668,\n",
      "         -0.3771, -0.5021,  0.1433,  2.1908],\n",
      "        [-0.4877, -0.4785, -0.3833,  2.1070, -0.4637, -0.5062, -0.3739, -0.4563,\n",
      "         -0.4617, -0.5045, -0.1611,  0.9805],\n",
      "        [-0.5010, -0.4633, -0.3947,  1.9161, -0.4553, -0.5075, -0.2735, -0.4674,\n",
      "         -0.4684, -0.5054, -0.3518,  1.5241],\n",
      "        [-0.3471, -0.4924, -0.3726,  1.8385, -0.4128, -0.4821, -0.5077, -0.4659,\n",
      "         -0.3857, -0.5018,  0.1018,  3.9465],\n",
      "        [-0.3471, -0.4965, -0.3726,  2.1480, -0.3781, -0.4684, -0.5077, -0.4649,\n",
      "         -0.3864, -0.5031,  0.1346,  3.9440],\n",
      "        [-0.4810, -0.4870, -0.3846,  2.1436, -0.4410, -0.5054, -0.5077, -0.4678,\n",
      "         -0.4420, -0.5043,  0.0055,  1.5260],\n",
      "        [-0.4743, -0.4554, -0.4087,  2.1076, -0.4671, -0.5074, -0.0394, -0.4618,\n",
      "         -0.4919, -0.5060, -0.1906,  1.8873],\n",
      "        [-0.4743, -0.4852, -0.3793,  2.1480, -0.4430, -0.5073, -0.5077, -0.4680,\n",
      "         -0.4690, -0.5053, -0.0514,  1.3574]]), tensor([[-0.2996],\n",
      "        [-0.2909],\n",
      "        [-0.3639],\n",
      "        [-0.2722],\n",
      "        [-0.3779],\n",
      "        [-0.3746],\n",
      "        [-0.4241],\n",
      "        [-0.3719],\n",
      "        [-0.3418],\n",
      "        [-0.3813]])]\n",
      "i_batch: 23\t-----batched_sample: [tensor([[-0.3471, -0.4904, -0.3726,  1.2001, -0.3979, -0.4755, -0.5077, -0.4629,\n",
      "         -0.3869, -0.5030,  0.0945,  3.9521],\n",
      "        [-0.4743, -0.4803, -0.4080,  2.1480, -0.4753, -0.5063, -0.3739, -0.4622,\n",
      "         -0.4852, -0.5043, -0.2923,  0.9358],\n",
      "        [-0.3471, -0.4947, -0.3726,  2.0571, -0.4200, -0.4118, -0.5077, -0.4661,\n",
      "         -0.3859, -0.5019,  0.0811,  3.9512],\n",
      "        [-0.4810, -0.4724, -0.3793,  2.0160, -0.4573, -0.5064, -0.5077, -0.4659,\n",
      "         -0.4347, -0.5052, -0.4662,  1.5367],\n",
      "        [-0.3471, -0.4929, -0.3726,  0.1656, -0.4062, -0.4146, -0.5077, -0.4662,\n",
      "         -0.3858, -0.5044,  0.1279,  3.9501],\n",
      "        [-0.3471, -0.4947, -0.3726,  1.4431, -0.4134, -0.4271, -0.5077, -0.4699,\n",
      "         -0.3860, -0.5037,  0.0784,  3.9468],\n",
      "        [-0.3471, -0.4930, -0.3726,  0.1477, -0.4272, -0.4646, -0.5077, -0.4647,\n",
      "         -0.3868, -0.5036, -0.0072,  3.9494],\n",
      "        [-0.4877, -0.4653, -0.4013,  2.0773, -0.4869, -0.5076,  0.0945, -0.4579,\n",
      "         -0.4824, -0.5050, -0.2789,  1.1245],\n",
      "        [-0.4743, -0.4915, -0.4094,  2.1360, -0.4298, -0.4927, -0.5077, -0.4686,\n",
      "         -0.3752, -0.5043,  0.1065,  2.1954],\n",
      "        [-0.3471, -0.4987, -0.3726,  2.0037, -0.4828, -0.4698, -0.5077, -0.4630,\n",
      "         -0.3869, -0.5043,  0.1400,  3.9486]]), tensor([[-0.3980],\n",
      "        [-0.2729],\n",
      "        [-0.3645],\n",
      "        [-0.3512],\n",
      "        [-0.4294],\n",
      "        [-0.3686],\n",
      "        [-0.4000],\n",
      "        [-0.2133],\n",
      "        [-0.3558],\n",
      "        [-0.1732]])]\n",
      "i_batch: 24\t-----batched_sample: [tensor([[-0.5010, -0.4932, -0.3672,  2.1480, -0.4700, -0.5073, -0.5077, -0.4611,\n",
      "         -0.4284, -0.5025,  0.1012,  1.3218],\n",
      "        [-0.4810, -0.4779, -0.3672,  2.0350, -0.4391, -0.5035, -0.5077, -0.4669,\n",
      "         -0.4536, -0.5047,  0.0577,  1.5469],\n",
      "        [-0.3471, -0.4920, -0.3726,  1.8696, -0.3891, -0.4713, -0.5077, -0.4632,\n",
      "         -0.3881, -0.5025,  0.1493,  3.9467],\n",
      "        [-0.3471, -0.4840, -0.3726,  2.1198, -0.4075, -0.4696, -0.5077, -0.4668,\n",
      "         -0.3863, -0.5040,  0.0262,  3.9502],\n",
      "        [-0.4810, -0.4724, -0.3793,  2.1079, -0.4708, -0.5071, -0.5077, -0.4672,\n",
      "         -0.4360, -0.5053, -0.4555,  1.5353],\n",
      "        [-0.4743, -0.4677, -0.3726,  2.1480, -0.4541, -0.5075, -0.5077, -0.4673,\n",
      "         -0.4736, -0.5055, -0.2769,  0.9893],\n",
      "        [-0.4609, -0.4710, -0.4000,  2.1403, -0.4442, -0.5075, -0.2802, -0.4636,\n",
      "         -0.4658, -0.5052, -0.2374,  1.6991],\n",
      "        [-0.4944, -0.4849, -0.3886,  2.1424, -0.4696, -0.5074, -0.5077, -0.4604,\n",
      "         -0.4863, -0.5048, -0.0855,  1.2993],\n",
      "        [-0.4542, -0.4858, -0.3913,  2.1044, -0.4413, -0.5036, -0.5077, -0.4617,\n",
      "         -0.4656, -0.5050,  0.0122,  1.5488],\n",
      "        [-0.4676, -0.4907, -0.3886,  2.1480, -0.3934, -0.5062, -0.5077, -0.4670,\n",
      "         -0.4387, -0.5031,  0.1306,  2.3759]]), tensor([[-0.3478],\n",
      "        [-0.3860],\n",
      "        [-0.4060],\n",
      "        [-0.3799],\n",
      "        [-0.3552],\n",
      "        [-0.3666],\n",
      "        [-0.3605],\n",
      "        [-0.3157],\n",
      "        [-0.3237],\n",
      "        [-0.3826]])]\n",
      "i_batch: 25\t-----batched_sample: [tensor([[-0.5010, -0.4469, -0.3860,  1.7780, -0.4212, -0.5076,  0.0276, -0.4660,\n",
      "         -0.4962, -0.5061, -0.2970,  1.1016],\n",
      "        [-0.4743, -0.4776, -0.3826,  2.1424, -0.4468, -0.5072, -0.5077, -0.4684,\n",
      "         -0.4233, -0.5059, -0.2628,  2.1510],\n",
      "        [-0.3471, -0.4909, -0.3726,  2.1068, -0.4230, -0.4792, -0.5077, -0.4668,\n",
      "         -0.3884, -0.5015,  0.0363,  3.9489],\n",
      "        [-0.4810, -0.4954, -0.3659,  2.1291, -0.4101, -0.5054, -0.5077, -0.4645,\n",
      "         -0.3615, -0.5042,  0.1507,  2.4139],\n",
      "        [-0.4743, -0.4729, -0.4080,  2.0153, -0.4876, -0.5073, -0.3739, -0.4566,\n",
      "         -0.4856, -0.5044, -0.1752,  0.9400],\n",
      "        [-0.4743, -0.4763, -0.4080,  2.0838, -0.4826, -0.5075, -0.3739, -0.4554,\n",
      "         -0.4857, -0.5055, -0.0762,  0.9381],\n",
      "        [-0.4877, -0.4541, -0.3819,  1.9319, -0.4230, -0.5073, -0.5077, -0.4683,\n",
      "         -0.4785, -0.5041, -0.1578,  1.8507],\n",
      "        [-0.4542, -0.4886, -0.3913,  2.1132, -0.4428, -0.5053, -0.5077, -0.4612,\n",
      "         -0.4668, -0.5049,  0.0844,  1.5441],\n",
      "        [-0.4743, -0.4755, -0.3726,  2.1429, -0.4508, -0.5075, -0.5077, -0.4672,\n",
      "         -0.4719, -0.5034, -0.2582,  0.9865],\n",
      "        [-0.3471, -0.4985, -0.3726,  2.1480, -0.3492, -0.3495, -0.5077, -0.4650,\n",
      "         -0.3868, -0.5024,  0.1360,  3.9542]]), tensor([[-0.3732],\n",
      "        [-0.3719],\n",
      "        [-0.3565],\n",
      "        [-0.3933],\n",
      "        [-0.1999],\n",
      "        [-0.2040],\n",
      "        [-0.3926],\n",
      "        [-0.3291],\n",
      "        [-0.3699],\n",
      "        [-0.4201]])]\n",
      "i_batch: 26\t-----batched_sample: [tensor([[-0.3471, -0.4810, -0.3726,  2.0926, -0.4369, -0.4832, -0.5077, -0.4655,\n",
      "         -0.3868, -0.5011, -0.1605,  3.9514],\n",
      "        [-0.4810, -0.4735, -0.3793,  2.1480, -0.4763, -0.5075,  0.0276, -0.4634,\n",
      "         -0.4742, -0.5055, -0.3512,  1.1317],\n",
      "        [-0.3471, -0.4895, -0.3726,  2.1382, -0.4309, -0.4729, -0.5077, -0.4667,\n",
      "         -0.3864, -0.5023,  0.0503,  3.9518],\n",
      "        [-0.4810, -0.4835, -0.3860,  2.1480, -0.4369, -0.5074, -0.3204, -0.4659,\n",
      "         -0.4071, -0.5047,  0.0095,  1.3016],\n",
      "        [-0.4609, -0.4481, -0.3799,  2.0757, -0.4841, -0.5072, -0.3605, -0.4612,\n",
      "         -0.4680, -0.5060, -0.4622,  1.7043],\n",
      "        [-0.3471, -0.4999, -0.3726,  1.9422, -0.4440, -0.4460, -0.5077, -0.4661,\n",
      "         -0.3857, -0.5026,  0.1614,  3.9531],\n",
      "        [-0.3471, -0.4968, -0.3726,  2.1226, -0.3744, -0.4564, -0.5077, -0.4693,\n",
      "         -0.3849, -0.5028,  0.1540,  3.9475],\n",
      "        [-0.4743, -0.4852, -0.3980,  2.1268, -0.4375, -0.5070, -0.5077, -0.4651,\n",
      "         -0.4139, -0.5044,  0.1105,  1.3426],\n",
      "        [-0.5010, -0.4489, -0.3759,  2.1008, -0.4683, -0.5075, -0.2401, -0.4613,\n",
      "         -0.4998, -0.5049, -0.2769,  1.7334],\n",
      "        [-0.4877, -0.4877, -0.3886,  2.1085, -0.4142, -0.5072, -0.5077, -0.4702,\n",
      "         -0.4929, -0.5045,  0.0931,  0.7790]]), tensor([[-0.3659],\n",
      "        [-0.3211],\n",
      "        [-0.3558],\n",
      "        [-0.3699],\n",
      "        [-0.3097],\n",
      "        [-0.1732],\n",
      "        [-0.4509],\n",
      "        [-0.3538],\n",
      "        [-0.3297],\n",
      "        [-0.3311]])]\n",
      "i_batch: 27\t-----batched_sample: [tensor([[-0.4810, -0.4783, -0.3672,  2.1308, -0.3987, -0.5027, -0.5077, -0.4681,\n",
      "         -0.4546, -0.5030,  0.1219,  1.5480],\n",
      "        [-0.4810, -0.4621, -0.3953,  2.1390, -0.4177, -0.5071, -0.3672, -0.4678,\n",
      "         -0.4710, -0.5031, -0.2019,  1.1129],\n",
      "        [-0.4676, -0.4890, -0.3793,  2.1238, -0.3900, -0.5065, -0.5077, -0.4698,\n",
      "         -0.4438, -0.5029, -0.3150,  2.1078],\n",
      "        [-0.4944, -0.4843, -0.3873,  2.1254, -0.4838, -0.5072, -0.5077, -0.4554,\n",
      "         -0.4894, -0.5060, -0.2608,  1.3395],\n",
      "        [-0.3471, -0.4890, -0.3726,  2.1274, -0.4389, -0.4688, -0.5077, -0.4642,\n",
      "         -0.3857, -0.5031,  0.0938,  3.9503],\n",
      "        [-0.4676, -0.4920, -0.3886,  2.1349, -0.3993, -0.5069, -0.5077, -0.4682,\n",
      "         -0.4404, -0.5048,  0.1139,  2.3814],\n",
      "        [-0.4743, -0.4935, -0.4207,  2.0621, -0.4088, -0.5025, -0.3739, -0.4608,\n",
      "         -0.4803, -0.5033,  0.0583,  1.2581],\n",
      "        [-0.4743, -0.4900, -0.3967,  2.1386, -0.4472, -0.5071, -0.5077, -0.4648,\n",
      "         -0.4809, -0.5040,  0.0550,  1.4753],\n",
      "        [-0.3471, -0.4909, -0.3726,  1.9985, -0.4556, -0.4773, -0.5077, -0.4649,\n",
      "         -0.3871, -0.5015,  0.0811,  3.9429],\n",
      "        [-0.3471, -0.4977, -0.3726,  1.7550, -0.3072, -0.4414, -0.5077, -0.4686,\n",
      "         -0.3877, -0.5044,  0.0128,  3.9476]]), tensor([[-0.4034],\n",
      "        [-0.3759],\n",
      "        [-0.3532],\n",
      "        [-0.2147],\n",
      "        [-0.3726],\n",
      "        [-0.3819],\n",
      "        [-0.3023],\n",
      "        [-0.3498],\n",
      "        [-0.3405],\n",
      "        [-0.4656]])]\n",
      "i_batch: 28\t-----batched_sample: [tensor([[-0.3471, -0.4905, -0.3726, -0.4376, -0.3805, -0.4765, -0.5077, -0.4677,\n",
      "         -0.3855, -0.5024,  0.0804,  3.9499],\n",
      "        [-0.4609, -0.4808, -0.3846,  2.1264, -0.4614, -0.5074, -0.2869, -0.4593,\n",
      "         -0.4920, -0.5043, -0.2327,  0.9718],\n",
      "        [-0.4743, -0.4761, -0.3766,  2.1480, -0.4668, -0.5055, -0.5077, -0.4648,\n",
      "         -0.4572, -0.5040, -0.2394,  1.4116],\n",
      "        [-0.4542, -0.4884, -0.3913,  2.0483, -0.4768, -0.5042, -0.5077, -0.4494,\n",
      "         -0.4661, -0.5033,  0.0476,  1.5442],\n",
      "        [-0.3471, -0.4948, -0.3726,  2.1315, -0.3932, -0.4611, -0.5077, -0.4695,\n",
      "         -0.3868, -0.5038,  0.1413,  3.9446],\n",
      "        [-0.4877, -0.4904, -0.3886,  2.1480, -0.4445, -0.5073, -0.5077, -0.4666,\n",
      "         -0.4914, -0.5043, -0.0915,  0.7849],\n",
      "        [-0.4810, -0.4936, -0.3659,  2.1355, -0.4234, -0.5055, -0.5077, -0.4645,\n",
      "         -0.3609, -0.5039,  0.1540,  2.4114],\n",
      "        [-0.4810, -0.4786, -0.3833,  2.1344, -0.4343, -0.5062, -0.5077, -0.4654,\n",
      "         -0.4346, -0.5041, -0.1564,  1.3476],\n",
      "        [-0.4810, -0.4936, -0.3659,  2.1331, -0.3943, -0.5040, -0.5077, -0.4653,\n",
      "         -0.3617, -0.5019,  0.1493,  2.4207],\n",
      "        [-0.3471, -0.4955, -0.3726, -0.3254, -0.3134, -0.3867, -0.5077, -0.4647,\n",
      "         -0.3877, -0.5050,  0.1614,  3.9433]]), tensor([[-0.4228],\n",
      "        [-0.2662],\n",
      "        [-0.3405],\n",
      "        [-0.1732],\n",
      "        [-0.4067],\n",
      "        [-0.2655],\n",
      "        [-0.3793],\n",
      "        [-0.3445],\n",
      "        [-0.3866],\n",
      "        [-0.4596]])]\n",
      "i_batch: 29\t-----batched_sample: [tensor([[-0.4542, -0.4832, -0.3913,  2.0091, -0.4726, -0.5046, -0.5077, -0.4581,\n",
      "         -0.4677, -0.5051,  0.0068,  1.5438],\n",
      "        [-0.3471, -0.4828, -0.3726,  1.9729, -0.4185, -0.4918, -0.5077, -0.4685,\n",
      "         -0.3880, -0.5046, -0.2274,  3.9515],\n",
      "        [-0.4810, -0.4724, -0.3793,  2.0599, -0.4628, -0.5071, -0.5077, -0.4648,\n",
      "         -0.4359, -0.5041, -0.4636,  1.5335],\n",
      "        [-0.4810, -0.4966, -0.3659,  2.1155, -0.3651, -0.5061, -0.5077, -0.4685,\n",
      "         -0.3600, -0.5034,  0.1493,  2.4153],\n",
      "        [-0.4810, -0.4798, -0.3672,  2.0130, -0.4205, -0.4987, -0.5077, -0.4671,\n",
      "         -0.4535, -0.5032,  0.1614,  1.5422],\n",
      "        [-0.4743, -0.4636, -0.4060,  2.0798, -0.3933, -0.5066, -0.4241, -0.4676,\n",
      "         -0.4548, -0.5047,  0.0670,  1.5731],\n",
      "        [-0.3471, -0.4937, -0.3726,  1.8307, -0.3411, -0.4072, -0.5077, -0.4722,\n",
      "         -0.3874, -0.5043,  0.1433,  3.9451],\n",
      "        [-0.3471, -0.4973, -0.3726, -0.3151, -0.2778, -0.3819, -0.5077, -0.4768,\n",
      "         -0.3858, -0.5024,  0.1614,  3.9530],\n",
      "        [-0.3471, -0.4943, -0.3726,  2.1399, -0.3967, -0.4698, -0.5077, -0.4661,\n",
      "         -0.3869, -0.5034,  0.1614,  3.9460],\n",
      "        [-0.4743, -0.4266, -0.3940,  2.0648, -0.4776, -0.5076,  0.0945, -0.4627,\n",
      "         -0.4962, -0.5063, -0.2662,  0.7419]]), tensor([[-0.2956],\n",
      "        [-0.3699],\n",
      "        [-0.3458],\n",
      "        [-0.4187],\n",
      "        [-0.4107],\n",
      "        [-0.3813],\n",
      "        [-0.4274],\n",
      "        [-0.3880],\n",
      "        [-0.3846],\n",
      "        [-0.3063]])]\n",
      "i_batch: 30\t-----batched_sample: [tensor([[-0.3471, -0.4935, -0.3726,  2.0197, -0.3900, -0.4476, -0.5077, -0.4662,\n",
      "         -0.3861, -0.5032,  0.1440,  3.9490],\n",
      "        [-0.4743, -0.4882, -0.3967,  2.1103, -0.4614, -0.5073, -0.5077, -0.4618,\n",
      "         -0.4812, -0.5049, -0.0099,  1.4705],\n",
      "        [-0.4944, -0.4938, -0.3799,  2.0221, -0.3878, -0.5071, -0.5077, -0.4678,\n",
      "         -0.3362, -0.5032,  0.1139,  0.7559]]), tensor([[-0.3886],\n",
      "        [-0.3077],\n",
      "        [-0.3706]])]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils import data\n",
    "class LDataset(data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_dataset = LDataset(normed_x_train, normed_y_train)\n",
    "test_dataset = LDataset(normed_x_test, normed_y_test)\n",
    "val_dataset = LDataset(normed_x_val, normed_y_val)\n",
    "\n",
    "test_dataloader = data.DataLoader(test_dataset, batch_size=5, shuffle=True, num_workers=5)\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=5)\n",
    "for i_batch, batched_sample in enumerate(train_dataloader):\n",
    "    print(f'i_batch: {i_batch}\\t-----batched_sample: {batched_sample}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\ttrain_loss,\tval_loss\n",
      "0\t1.4305\t\t1.3472\n",
      "5000\t0.0031\t\t0.0032\n",
      "10000\t0.0027\t\t0.0029\n",
      "15000\t0.0026\t\t0.0028\n",
      "20000\t0.0024\t\t0.0027\n",
      "25000\t0.0024\t\t0.0027\n",
      "30000\t0.0023\t\t0.0026\n",
      "35000\t0.0023\t\t0.0026\n",
      "40000\t0.0023\t\t0.0026\n",
      "45000\t0.0022\t\t0.0026\n",
      "50000\t0.0022\t\t0.0025\n",
      "55000\t0.0022\t\t0.0025\n",
      "60000\t0.0022\t\t0.0025\n",
      "65000\t0.0022\t\t0.0025\n",
      "70000\t0.0022\t\t0.0025\n",
      "75000\t0.0021\t\t0.0025\n",
      "80000\t0.0021\t\t0.0024\n",
      "85000\t0.0021\t\t0.0024\n",
      "90000\t0.0021\t\t0.0024\n",
      "95000\t0.0021\t\t0.0024\n"
     ]
    }
   ],
   "source": [
    "def basic_linear_train(x_train, y_train, x_val, y_val, epoch, lr=0.01, save_model=False, gpu=False, vis=False):\n",
    "    \"\"\"The default train function without regularization\"\"\"\n",
    "\n",
    "    model = torch.nn.Linear(12, 1, bias=True)  # define Linear model\n",
    "    loss_func = torch.nn.MSELoss()  # define loss function\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.001)  # define optimizer\n",
    "\n",
    "    if gpu:\n",
    "        model = model.cuda(0)\n",
    "        x_train = x_train.cuda(0)\n",
    "        y_train = y_train.cuda(0)\n",
    "        x_val = x_val.cuda(0)\n",
    "        y_val = y_val.cuda(0)\n",
    "\n",
    "    print('iter,\\ttrain_loss,\\tval_loss')\n",
    "\n",
    "    for i in range(epoch):\n",
    "        \"\"\"Train process\"\"\"\n",
    "        y_hat = model(x_train)\n",
    "        loss = loss_func(y_hat, y_train)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(model.weight.detach().numpy())\n",
    "        \"\"\"validation process\"\"\"\n",
    "        y_val_hat = model(x_val)\n",
    "        loss_val = loss_func(y_val_hat, y_val)\n",
    "        # print(model.weight.detach().numpy())\n",
    "        \"\"\"print the train loss and validation loss\"\"\"\n",
    "        if i % 5000 == 0:\n",
    "            print(f'{i}\\t{loss.item():.4f}\\t\\t{loss_val.item():.4f}')\n",
    "    if save_model:\n",
    "        torch.save(model, './LinearModel.pth')\n",
    "\n",
    "basic_linear_train(normed_x_train, normed_y_train, normed_x_val, normed_y_val, 100000, 0.001, save_model=True, gpu=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Task 1 - C: Linear Regression Training\n",
    "\n",
    "In this section we will define the Linear models and fit them with PyTorch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\ttrain_loss,\tval_loss\n",
      "0\t0.5777\t\t0.5492\n",
      "5000\t0.0026\t\t0.0028\n",
      "10000\t0.0025\t\t0.0028\n",
      "15000\t0.0025\t\t0.0028\n",
      "20000\t0.0024\t\t0.0027\n",
      "25000\t0.0024\t\t0.0027\n",
      "30000\t0.0024\t\t0.0027\n",
      "35000\t0.0024\t\t0.0027\n",
      "40000\t0.0024\t\t0.0027\n",
      "45000\t0.0023\t\t0.0026\n",
      "50000\t0.0023\t\t0.0026\n",
      "55000\t0.0023\t\t0.0026\n",
      "60000\t0.0023\t\t0.0026\n",
      "65000\t0.0023\t\t0.0026\n",
      "70000\t0.0023\t\t0.0026\n",
      "75000\t0.0022\t\t0.0025\n",
      "80000\t0.0022\t\t0.0025\n",
      "85000\t0.0022\t\t0.0025\n",
      "90000\t0.0022\t\t0.0025\n",
      "95000\t0.0022\t\t0.0025\n"
     ]
    }
   ],
   "source": [
    "def basic_linear_train(x_train, y_train, x_val, y_val, epoch, lr=0.01, save_model=False):\n",
    "    \"\"\"The default train function without regularization\"\"\"\n",
    "\n",
    "    model = torch.nn.Linear(12, 1, bias=True)  # define Linear model\n",
    "    loss_func = torch.nn.MSELoss()  # define loss function\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=lr, weight_decay=0.001)  # define optimizer\n",
    "\n",
    "    print('iter,\\ttrain_loss,\\tval_loss')\n",
    "\n",
    "    for i in range(epoch):\n",
    "        \"\"\"Train process\"\"\"\n",
    "        y_hat = model(x_train)\n",
    "        loss = loss_func(y_hat, y_train)\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(model.weight.detach().numpy())\n",
    "        \"\"\"validation process\"\"\"\n",
    "        y_val_hat = model(x_val)\n",
    "        loss_val = loss_func(y_val_hat, y_val)\n",
    "        # print(model.weight.detach().numpy())\n",
    "        \"\"\"print the train loss and validation loss\"\"\"\n",
    "        if i % 5000 == 0:\n",
    "            print(f'{i}\\t{loss.item():.4f}\\t\\t{loss_val.item():.4f}')\n",
    "    if save_model:\n",
    "        torch.save(model, './LinearModel.pth')\n",
    "\n",
    "basic_linear_train(normed_x_train, normed_y_train, normed_x_val, normed_y_val, 100000, 0.001, save_model=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "def test_data(model_path, x_test, y_test, visualize=False):\n",
    "    model = torch.load(model_path)\n",
    "    loss_func = torch.nn.MSELoss()\n",
    "    predict = model(x_test)\n",
    "    loss = loss_func(y_test, predict)\n",
    "    print(f'test loss: {loss:.4f}')\n",
    "\n",
    "test_data('./LinearModel.pth', normed_x_test.cuda(0), normed_y_test.cuda(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\ttrain_loss,\tval_loss\n",
      "0\t0.0370\t\t0.0402\n",
      "5000\t0.0101\t\t0.0109\n",
      "10000\t0.0061\t\t0.0060\n",
      "15000\t0.0050\t\t0.0047\n",
      "20000\t0.0047\t\t0.0043\n",
      "25000\t0.0045\t\t0.0041\n",
      "30000\t0.0043\t\t0.0039\n",
      "35000\t0.0041\t\t0.0038\n",
      "40000\t0.0040\t\t0.0037\n",
      "45000\t0.0039\t\t0.0036\n",
      "50000\t0.0038\t\t0.0036\n",
      "55000\t0.0037\t\t0.0035\n",
      "60000\t0.0037\t\t0.0035\n",
      "65000\t0.0036\t\t0.0035\n",
      "70000\t0.0035\t\t0.0034\n",
      "75000\t0.0035\t\t0.0034\n",
      "80000\t0.0035\t\t0.0034\n",
      "85000\t0.0034\t\t0.0034\n",
      "90000\t0.0034\t\t0.0034\n",
      "95000\t0.0034\t\t0.0033\n",
      "test loss: 0.0027\n"
     ]
    }
   ],
   "source": [
    "def linear_L1(x_train, y_train, x_val, y_val, epoch, lr=0.001, save_model=False, gpu=False, vis=False):\n",
    "\n",
    "    model = torch.nn.Linear(12, 1, bias=True)  # define Linear model\n",
    "    loss_func = torch.nn.MSELoss()  # define loss function\n",
    "    optim = torch.optim.SGD(model.parameters(), lr=lr)  # define optimizer\n",
    "\n",
    "    if gpu:\n",
    "        model = model.cuda(0)\n",
    "        x_train = x_train.cuda(0)\n",
    "        y_train = y_train.cuda(0)\n",
    "        x_val = x_val.cuda(0)\n",
    "        y_val = y_val.cuda(0)\n",
    "    print('iter,\\ttrain_loss,\\tval_loss')\n",
    "\n",
    "    for i in range(epoch):\n",
    "        \"\"\"Train process\"\"\"\n",
    "        w = 0\n",
    "        for param in model.parameters():\n",
    "            w += torch.sum(abs(param))\n",
    "        y_hat = model(x_train)\n",
    "        loss = loss_func(y_hat, y_train) + 0.001 * w\n",
    "        optim.zero_grad()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        # print(model.weight.detach().numpy())\n",
    "        \"\"\"validation process\"\"\"\n",
    "        y_val_hat = model(x_val)\n",
    "        loss_val = loss_func(y_val_hat, y_val)\n",
    "        # print(model.weight.detach().numpy())\n",
    "        \"\"\"print the train loss and validation loss\"\"\"\n",
    "        if i % 5000 == 0:\n",
    "            print(f'{i}\\t{loss.item():.4f}\\t\\t{loss_val.item():.4f}')\n",
    "    if save_model:\n",
    "        torch.save(model, './LinearModel_L1.pth')\n",
    "\n",
    "linear_L1(normed_x_train, normed_y_train, normed_x_val, normed_y_val, 100000, lr=0.001, save_model=True, gpu=True)\n",
    "test_data('./LinearModel_L1.pth', normed_x_test.cuda(0), normed_y_test.cuda(0))\n",
    "\n",
    "# TODO: Revise test_data function, refer the materials, re-write mse, rmse, mae. Implement them for q-3.\n",
    "# TODO: Try to draw the graph for observation. \n",
    "# TODO: Finish the report part, start task 2. "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}