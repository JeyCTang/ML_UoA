{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# PyTorch Introduction\n",
    "\n",
    "Goal takeways:\n",
    "- Automatic differentiation is a powerful tool\n",
    "- PyTorch implements common function used in deep learning\n",
    "- Data Processing with PyTorch DataSet\n",
    "- Mixed Presision Training in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "torch.manual_seed(446)\n",
    "np.random.seed(446)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensors and relation to numpy\n",
    "\n",
    "By this point, we have worked with numpy quite a bit. PyTorch's building block, the `tensor` is similar to numpy's `ndarray`."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_numpy, x_torch\n",
      "[0.1 0.2 0.3] tensor([0.1000, 0.2000, 0.3000])\n",
      "\n",
      "to and from numpy and pytorch\n",
      "tensor([0.1000, 0.2000, 0.3000], dtype=torch.float64) [0.1 0.2 0.3]\n",
      "\n",
      "x + y\n",
      "[3.1 4.2 5.3] tensor([3.1000, 4.2000, 5.3000])\n",
      "\n",
      "norm\n",
      "0.37416573867739417 tensor(0.3742)\n",
      "\n",
      "mean along the 0th dimension\n",
      "[2. 3.] tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# we create tensors in a similar way to numpy nd arrays\n",
    "x_numpy = np.array([0.1, 0.2, 0.3])\n",
    "x_torch = torch.tensor([0.1, 0.2, 0.3])\n",
    "print('x_numpy, x_torch')\n",
    "print(x_numpy, x_torch)\n",
    "print()\n",
    "\n",
    "# to and from numpy, pytorch\n",
    "print('to and from numpy and pytorch')\n",
    "print(torch.from_numpy(x_numpy), x_torch.numpy())\n",
    "print()\n",
    "\n",
    "# we can do basic operations like +-*/\n",
    "y_numpy = np.array([3, 4, 5.])\n",
    "y_torch = torch.tensor([3, 4, 5])\n",
    "print('x + y')\n",
    "print(x_numpy + y_numpy, x_torch + y_torch)\n",
    "print()\n",
    "\n",
    "# many functions that are in numpy are also in pytorch\n",
    "print(\"norm\")\n",
    "print(np.linalg.norm(x_numpy), torch.norm(x_torch))\n",
    "print()\n",
    "\n",
    "# to apply an operation along a dimension,\n",
    "# we use the dim keyword argument instead of axis\n",
    "print('mean along the 0th dimension')\n",
    "x_numpy = np.array([[1, 2.], [3, 4.]])\n",
    "x_torch = torch.tensor([[1, 2.], [3, 4.]])\n",
    "print(np.mean(x_numpy, axis=0), torch.mean(x_torch, dim=0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `Tensor.view`\n",
    "We can use the `Tensor.view()` function to reshape tensors similarly to `numpy.reshape()`\n",
    "\n",
    "It can also automatically calculate the correct dimension of `a - 1` is passed in. This is useful if we are working with\n",
    "batches, but the batch size is unknown."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 3, 28, 28])\n",
      "torch.Size([10000, 3, 784])\n",
      "torch.Size([10000, 3, 784])\n"
     ]
    }
   ],
   "source": [
    "# MNIST\n",
    "N, C, W, H = 10000, 3, 28, 28\n",
    "X = torch.randn((N, C, W, H))\n",
    "\n",
    "print(X.shape)\n",
    "print(X.view(N, C, 784).shape)\n",
    "print(X.view(-1, C, 784).shape)  # automatically choose the 0th dimension"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Broadcasting Semantics\n",
    "Two tensors are \"Broadcastable\" if the following rules hold:\n",
    "- Each tensor has at least one dimension\n",
    "- When iterating over the dimension sizes, starting at the trailing dimension, the dimension sizes must either be equal,\n",
    "one of them is 1, or one of them does not exist."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4, 1])\n"
     ]
    }
   ],
   "source": [
    "# PyTorch operations support NumPy Broadcasting Semantics\n",
    "x = torch.empty(5, 1, 4, 1)\n",
    "y = torch.empty(3, 1, 1)\n",
    "print((x + y).size())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computation graphs\n",
    "\n",
    "What's special about PyTorch's `tensor` object is that it implicitly creates a computation graph in the background. A\n",
    "computation graph is a way of writing a mathematical expression as a graph. There is an algorithm to compute the gradients\n",
    "of all the variable of a computation graph in time on the same order it is to compute the function itself.\n",
    "\n",
    "Consider the expression $e = (a+b) * (b+1)$ with values $a=2, b=1$. We can draw the evaluated computation graph as in\n",
    "PyTorch, we can write this as\n",
    "\n",
    "[![](https://mermaid.ink/img/eyJjb2RlIjoiZ3JhcGggVERcbiAgICBFKGUgPSBjKmQsZT02KVxuICAgIEMoYyA9IGErYiwgYyA9IDMpXG4gICAgRChkID0gYisxLCBkID0gMilcbiAgICBBKGEsIGE9MilcbiAgICBCKGIsIGI9MSlcbiAgICBBIC0tPiBDXG4gICAgQiAtLT4gQ1xuICAgIEMgLS0-IEVcbiAgICBEIC0tPiBFIiwibWVybWFpZCI6eyJ0aGVtZSI6ImRlZmF1bHQifSwidXBkYXRlRWRpdG9yIjpmYWxzZSwiYXV0b1N5bmMiOnRydWUsInVwZGF0ZURpYWdyYW0iOmZhbHNlfQ)](https://mermaid-js.github.io/mermaid-live-editor/edit#eyJjb2RlIjoiZ3JhcGggVERcbiAgICBFKGUgPSBjKmQsZT02KVxuICAgIEMoYyA9IGErYiwgYyA9IDMpXG4gICAgRChkID0gYisxLCBkID0gMilcbiAgICBBKGEsIGE9MilcbiAgICBCKGIsIGI9MSlcbiAgICBBIC0tPiBDXG4gICAgQiAtLT4gQ1xuICAgIEMgLS0-IEVcbiAgICBEIC0tPiBFIiwibWVybWFpZCI6IntcbiAgXCJ0aGVtZVwiOiBcImRlZmF1bHRcIlxufSIsInVwZGF0ZUVkaXRvciI6ZmFsc2UsImF1dG9TeW5jIjp0cnVlLCJ1cGRhdGVEaWFncmFtIjpmYWxzZX0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "2.0\n",
      "6.0\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(2.0, requires_grad=True)  # we set requires_grad=True to let PyTorch know to keep the graph\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "c = a + b\n",
    "d = b + 1\n",
    "e = c * d\n",
    "print(f'{c}')\n",
    "print(f'{d}')\n",
    "print(f'{e}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We can see that PyTorch kept track of the computation graph for us."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CUDA Semantics\n",
    "\n",
    "It's easy copy tensor from cpu to gpu or from gpu to cpu."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
      "        0.1897])\n",
      "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
      "        0.1897], device='cuda:0')\n",
      "tensor([0.3959, 0.6177, 0.7256, 0.0971, 0.9186, 0.8277, 0.4409, 0.9344, 0.8967,\n",
      "        0.1897])\n"
     ]
    }
   ],
   "source": [
    "cpu = torch.device(\"cpu\")\n",
    "\n",
    "# on Colab we should set torch.device(\"gpu\"), on personal computer with single GPU we set cuda\n",
    "gpu = torch.device(\"cuda\")\n",
    "\n",
    "x = torch.rand(10)\n",
    "print(x)\n",
    "x = x.to(gpu)\n",
    "print(x)\n",
    "x = x.to(cpu)\n",
    "print(x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PyTorch as an auto grad framework\n",
    "\n",
    "Now that we have seen PyTorch keeps the graph around for us, let's use it to compute some gradients for us.\n",
    "\n",
    "Consider the function $f(x) = (x-2)^2$\n",
    "\n",
    "Q: Compute $\\frac{df(x)}{dx}$ and then compute $f'(1)$\n",
    "\n",
    "We make a backward() call on the leaf variable(y) in the computation, computing all the gradients of `y` at once."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical f'(x): tensor([-2.], grad_fn=<MulBackward0>)\n",
      "PyTorch's f'(x): tensor([-2.])\n"
     ]
    }
   ],
   "source": [
    "def f(x):\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "\n",
    "def fp(x):\n",
    "    return 2 * (x - 2)\n",
    "\n",
    "\n",
    "x = torch.tensor([1.0], requires_grad=True)\n",
    "\n",
    "y = f(x)\n",
    "y.backward()\n",
    "\n",
    "print(f'Analytical f\\'(x): {fp(x)}')\n",
    "print(f'PyTorch\\'s f\\'(x): {x.grad}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "It can also find gradients of functions.\n",
    "\n",
    "Let $\\omega = [\\omega_1, \\omega_2]^T$\n",
    "\n",
    "Consider $g(\\omega) = 2\\omega_1\\omega_2 + \\omega_2 \\cos(\\omega_1)$\n",
    "\n",
    "Q: Compute $\\nabla_{\\omega}g(\\omega) and verify \\nabla_{\\omega}g([\\pi, 1]) = [2, \\pi - 1]^T$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def g(w):\n",
    "    return 2 * w[0] * w[1] + w[1] * torch.cos(w[0])\n",
    "\n",
    "\n",
    "def grad_g(w):\n",
    "    return torch.tensor([2 * w[1] - w[1] * torch.sin(w[0]), 2 * w[0] + torch.cos(w[0])])\n",
    "\n",
    "w = torch.tensor([np.pi, 1], requires_grad=True)\n",
    "\n",
    "z = g(w)\n",
    "z.backward()\n",
    "\n",
    "print(f'Analytical grad g(w): {grad_g(w)}')\n",
    "print(f'Pytorch\\s grad(w): {w.grad}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical grad g(w): tensor([2.0000, 5.2832])\n",
      "Pytorch\\s grad(w): tensor([2.0000, 5.2832])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Using the gradients\n",
    "\n",
    "Now that we have gradients, we can use our favorite optimization algorithm, gradient descent!\n",
    "\n",
    "Let $f% the same function we defined above.\n",
    "\n",
    "Q: What is the value of $x$ that minimizes $f$?"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the result: 5.000\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([5.0], requires_grad=True)\n",
    "step_size = 0.25\n",
    "\n",
    "print(f'This is the result: {x.item():.3f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter, \tx, \tf(x), \tf'(x), \tf'(x) pytorch\n",
      "0 \t5.000 \t9.000 \t6.000 \t6.000\n",
      "1 \t3.500 \t2.250 \t3.000 \t3.000\n",
      "2 \t2.750 \t0.562 \t1.500 \t1.500\n",
      "3 \t2.375 \t0.141 \t0.750 \t0.750\n",
      "4 \t2.188 \t0.035 \t0.375 \t0.375\n",
      "5 \t2.094 \t0.009 \t0.188 \t0.188\n",
      "6 \t2.047 \t0.002 \t0.094 \t0.094\n",
      "7 \t2.023 \t0.001 \t0.047 \t0.047\n",
      "8 \t2.012 \t0.000 \t0.023 \t0.023\n",
      "9 \t2.006 \t0.000 \t0.012 \t0.012\n",
      "10 \t2.003 \t0.000 \t0.006 \t0.006\n",
      "11 \t2.001 \t0.000 \t0.003 \t0.003\n",
      "12 \t2.001 \t0.000 \t0.001 \t0.001\n",
      "13 \t2.000 \t0.000 \t0.001 \t0.001\n",
      "14 \t2.000 \t0.000 \t0.000 \t0.000\n"
     ]
    }
   ],
   "source": [
    "print('iter, \\tx, \\tf(x), \\tf\\'(x), \\tf\\'(x) pytorch')\n",
    "for i in range(15):\n",
    "    y = f(x)\n",
    "    y.backward()  # compute the gradient\n",
    "\n",
    "    # print(\"{}, \\t{:.3f}, \\t{:.3f}, \\t{:.3f}, \\t{:.3f}\".format(i, x.item(), f(x).item(), fp(x).item, x.grad.item()))\n",
    "    print(f'{i} \\t{x.item():.3f} \\t{f(x).item():.3f} \\t{fp(x).item():.3f} \\t{x.grad.item():.3f}')\n",
    "    x.data = x.data - step_size * x.grad  # perform a GD update step\n",
    "\n",
    "    # We need to zero the grad variable since the backward()\n",
    "    # call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach_() is for efficiency. You do not need to worry to much about it.\n",
    "    x.grad.detach_()\n",
    "    x.grad.zero_()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Regression\n",
    "\n",
    "Now, instead of minimizing a made-up function, let's minimize a loss function on some made-up data.\n",
    "\n",
    "We will implement Gradient Descent in order to solve the task of linear regression.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape torch.Size([50, 2])\n",
      "y shape torch.Size([50, 1])\n",
      "w shape torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "# make a simple linear dataset with some noise\n",
    "d = 2\n",
    "n = 50\n",
    "X = torch.randn(n, d)\n",
    "true_w = torch.tensor([[-1.0], [2.0]])\n",
    "y = X @ true_w + torch.randn(n, 1) * 0.1\n",
    "\n",
    "print('X shape', X.shape)\n",
    "print('y shape', y.shape)\n",
    "print('w shape', true_w.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Note: dimensions\n",
    "\n",
    "PyTorch does a lot of operations on batches of data. The convention is to have your data be of size $(N, d)$ where $N$ is\n",
    "the size of the batch of data.\n",
    "\n",
    "## Sanity check\n",
    "\n",
    "To verify PyTorch is computing the gradients correctly, let's recall the gradient for the RSS objective:\n",
    "\n",
    "$\n",
    "\\nabla L_{RSS}(\\omega, X) = \\nabla_{\\omega}\\frac{1}{n}||y-X\\omega||_{2}^{2} = -\\frac{2}{n}X^T(y-X\\omega)\n",
    "$"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analytical gradient [ 4.342543  -3.5023162]\n",
      "PyTorch's gradient [ 4.342543 -3.502316]\n"
     ]
    }
   ],
   "source": [
    "# define a linear model with no bias\n",
    "def model(X, w):\n",
    "    return X @ w\n",
    "\n",
    "# the residual sum of squares loss function\n",
    "def rss(y, y_hat):\n",
    "    return torch.norm(y - y_hat)**2 / n\n",
    "\n",
    "# analytical expression for the gradient\n",
    "def grad_rss(X, y, w):\n",
    "    return -2 * X.t() @ (y - X @ w) / n\n",
    "\n",
    "w = torch.tensor([[1.], [0]], requires_grad=True)\n",
    "y_hat = model(X, w)\n",
    "\n",
    "loss = rss(y, y_hat)\n",
    "loss.backward()\n",
    "\n",
    "print('Analytical gradient', grad_rss(X, y, w).detach().view(2).numpy())\n",
    "print('PyTorch\\'s gradient', w.grad.view(2).numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now that we've seen PyTorch is doing the right think, let's use the gradients!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear regression using GD with automatically computed derivatives\n",
    "\n",
    "We will now use the gradients to run the gradient descent algorithm.\n",
    "\n",
    "Note: This example is an illustration to connect ideas we have seen before to PyTorch's way of doing things. We will see how\n",
    "to do this in the 'PyTorchic\" way in the next example."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0\t7.82\t[0.13149136 0.70046324]\n",
      "1\t2.84\t[-0.11822014  0.9229876 ]\n",
      "2\t1.84\t[-0.31444427  1.1054724 ]\n",
      "3\t1.19\t[-0.4684834  1.2552956]\n",
      "4\t0.77\t[-0.58927345  1.3784461 ]\n",
      "5\t0.50\t[-0.68387645  1.4797904 ]\n",
      "6\t0.33\t[-0.75787055  1.563287  ]\n",
      "7\t0.22\t[-0.8156596  1.632159 ]\n",
      "8\t0.15\t[-0.86071837  1.6890337 ]\n",
      "9\t0.10\t[-0.89578694  1.736055  ]\n",
      "10\t0.07\t[-0.9230244  1.7749742]\n",
      "11\t0.05\t[-0.94413096  1.8072236 ]\n",
      "12\t0.03\t[-0.9604442  1.8339758]\n",
      "13\t0.02\t[-0.9730157  1.8561921]\n",
      "14\t0.02\t[-0.9826713  1.8746614]\n",
      "15\t0.01\t[-0.99005884  1.8900318 ]\n",
      "16\t0.01\t[-0.99568594  1.9028363 ]\n",
      "17\t0.01\t[-0.99994993  1.913514  ]\n",
      "18\t0.01\t[-1.0031612  1.9224268]\n",
      "19\t0.01\t[-1.0055621  1.9298735]\n",
      "\n",
      "True w\t\t [-1.  2.]\n",
      "estimated w\t [-1.0055621  1.9298735]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.1\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(20):\n",
    "    y_hat = model(X, w)\n",
    "    loss = rss(y, y_hat)\n",
    "\n",
    "    loss.backward()  # compute the gradient of the loss\n",
    "\n",
    "    w.data = w.data - step_size * w.grad  # do a gradient descent step\n",
    "\n",
    "    print(f'{i}\\t{loss.item():.2f}\\t{w.view(2).detach().numpy()}')\n",
    "\n",
    "    # We need to zero the grad variable since the backward() call accumulates the gradients in .grad instead of overwriting.\n",
    "    # The detach() is for efficiency. You do not need to worry too much about it.\n",
    "    w.grad.detach()\n",
    "    w.grad.zero_()\n",
    "\n",
    "print('\\nTrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', w.view(2).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## torch.nn.Module\n",
    "\n",
    "Module is PyTorch's way of performing operation on tensors. Modules are implemented as subclasses of the `torch.nn.Module` class.\n",
    "All modules are callable and can be composed together to create complex functions.\n",
    "\n",
    "[torch.nn.docs](https://pytorch.org/docs/stable/nn.html)\n",
    "\n",
    "Note: most of the functionality implemented for modules can be accessed in a functional form via `torch.nn.functional` but\n",
    "these require you to create and manage the weight tensors yourself.\n",
    "\n",
    "[torch.nn.functional](https://pytorch.org/docs/stable/nn.functional.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear Module\n",
    "\n",
    "The bread and butter of modules is the Linear module which does a linear transformation with a bias. It takes the input and\n",
    "output dimensions as parameters, and creates the weights in the object.\n",
    "\n",
    "Unlike how we initialized our $\\omega$ manually, the Linear module automatically initializes the weights randomly. For minimizing\n",
    "non convex loss functions (e.g. training neural networks), initialization is important and can affect results. If training isn't working\n",
    "as well as expected, one thing to try is manually initializing the weights to something different from the default. PyTorch\n",
    "implements some common initializations in `torch.nn.init`.\n",
    "\n",
    "(torch.nn.imit.docs)[https://pytorch.org/docs/stable/nn.init.html]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor torch.Size([2, 3])\n",
      "transformed torch.Size([2, 4])\n",
      "\n",
      "We can see that the weights exist in the background\n",
      "\n",
      "W: Parameter containing:\n",
      "tensor([[ 0.5260,  0.4925, -0.0887],\n",
      "        [ 0.3944,  0.4080,  0.2182],\n",
      "        [-0.1409,  0.0518,  0.3034],\n",
      "        [ 0.0913,  0.2452, -0.2616]], requires_grad=True)\n",
      "b: Parameter containing:\n",
      "tensor([0.5021, 0.0118, 0.1383, 0.4757], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "d_in = 3\n",
    "d_out = 4\n",
    "linear_module = nn.Linear(d_in, d_out)\n",
    "\n",
    "example_tensor = torch.tensor(([[1., 2, 3], [4., 5, 6]]))\n",
    "#  applys a linear transformation to the data\n",
    "transformed = linear_module(example_tensor)\n",
    "\n",
    "print('example_tensor', example_tensor.shape)\n",
    "print('transformed', transformed.shape)\n",
    "print()\n",
    "print('We can see that the weights exist in the background\\n')\n",
    "print('W:', linear_module.weight)\n",
    "print('b:', linear_module.bias)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Activation functions\n",
    "\n",
    "PyTorch implements a number of activation functions including but not limited to ReLU, Tanh, and Sigmoid. Since they are\n",
    "modules, they need to be instantiated."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example_tensor tensor([-1.,  1.,  0.])\n",
      "activated tensor([0., 1., 0.])\n"
     ]
    }
   ],
   "source": [
    "activation_fn = nn.ReLU()  # we instantiate an instance of the ReLU module\n",
    "example_tensor = torch.tensor([-1.0, 1.0, 0.0])\n",
    "activated = activation_fn(example_tensor)\n",
    "print('example_tensor', example_tensor)\n",
    "print('activated', activated)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Sequential\n",
    "\n",
    "Many times, we want to compose Modules together. `torch.nn.Sequential` provides a good interface for composing simple modules."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformed torch.Size([2, 1])\n"
     ]
    }
   ],
   "source": [
    "d_in = 3\n",
    "d_hidden = 4\n",
    "d_out = 1\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(d_in, d_hidden),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(d_hidden, d_out),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "\n",
    "# below codes are equivalent\n",
    "# linear = nn.Linear(d_in, d_hidden)\n",
    "# tahn = nn.Tanh()\n",
    "# linear_2 = nn.Linear(d_hidden, d_out)\n",
    "# sigmod = nn.Sigmoid()\n",
    "#\n",
    "# x = linear(x)\n",
    "# x = tahn(x)\n",
    "# x = linear_2(x)\n",
    "# x = sigmod\n",
    "\n",
    "example_tensor = torch.tensor([[1., 2, 3], [4, 5, 6]])\n",
    "transformed = model(example_tensor)\n",
    "print('transformed', transformed.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Note: we can access all of the parameters (of any `nn.Module`) with the parameters() method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3128,  0.2707, -0.3952],\n",
      "        [ 0.1285,  0.1777, -0.4675],\n",
      "        [ 0.0452, -0.5630, -0.1999],\n",
      "        [ 0.5431,  0.0524,  0.1126]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2683, -0.2361,  0.2769, -0.1380], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.4902, -0.0928, -0.2907,  0.0734]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0394], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "params = model.parameters()\n",
    "for param in params:\n",
    "    print(param)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Loss functions\n",
    "\n",
    "PyTorch implements many common loss functions including MSELoss and CrossEntropyLoss"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "input_t = torch.tensor([0., 0, 0])\n",
    "target = torch.tensor([1., 0, -1])\n",
    "\n",
    "loss = mse_loss_fn(input_t, target)\n",
    "\n",
    "print(loss)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## `troch.optim`\n",
    "\n",
    "PyTorch implements a number of gradient-based optimization methods in `torch.optim`, including Gradient Descent. At the minimum,\n",
    "it takes in the model parameters and a learning rate.\n",
    "\n",
    "Optimizers do not compute the gradients for you, so you must call `backward()` yourself. You also must call the `optim.zero_grad()` function\n",
    "before calling `backward()` since by default PyTorch does and inplace add to the `.grad` member variable rather than overwriting it.\n",
    "\n",
    "This does both the `detach()` and `zero()` calls on all tensor's grad variables.\n",
    "\n",
    "(torch.optim.docs)[https://pytorch.org/docs/stable/optim.html]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model params before: Parameter containing:\n",
      "tensor([[-0.4950]], requires_grad=True)\n",
      "model params after Parameter containing:\n",
      "tensor([[-0.4427]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# create a simple model\n",
    "model = nn.Linear(1, 1)\n",
    "\n",
    "# create a simple dataset\n",
    "X_simple = torch.tensor([[1.]])\n",
    "y_simple = torch.tensor([[2.]])\n",
    "\n",
    "# create our optimizer\n",
    "optim = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "\n",
    "y_hat = model(X_simple)\n",
    "print('model params before:', model.weight)\n",
    "loss = mse_loss_fn(y_hat, y_simple)\n",
    "optim.zero_grad()\n",
    "loss.backward()\n",
    "optim.step()\n",
    "print('model params after', model.weight)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the parameter was updated in the correct direction"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear regression using GD with automatically computed derivatives and PyTorch's Modules\n",
    "\n",
    "Now let's combine what we've learned to solve linear regression in a \"PyTorchic\" way."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0\t2.99\t[-0.5453574   0.51412684]\n",
      "1\t2.02\t[-0.666086    0.75222915]\n",
      "2\t1.37\t[-0.75831056  0.9504565 ]\n",
      "3\t0.94\t[-0.82842976  1.1156546 ]\n",
      "4\t0.64\t[-0.8814486  1.2534634]\n",
      "5\t0.44\t[-0.92127615  1.3685349 ]\n",
      "6\t0.31\t[-0.9509604  1.4647106]\n",
      "7\t0.22\t[-0.9728737  1.5451664]\n",
      "8\t0.15\t[-0.98885876  1.6125307 ]\n",
      "9\t0.11\t[-1.0003437  1.6689818]\n",
      "10\t0.08\t[-1.0084321  1.7163262]\n",
      "11\t0.06\t[-1.0139749  1.7560644]\n",
      "12\t0.04\t[-1.0176253  1.7894436]\n",
      "13\t0.03\t[-1.0198835  1.8175017]\n",
      "14\t0.02\t[-1.0211303  1.8411033]\n",
      "15\t0.02\t[-1.0216544  1.8609697]\n",
      "16\t0.02\t[-1.0216731  1.8777025]\n",
      "17\t0.01\t[-1.0213491  1.8918046]\n",
      "18\t0.01\t[-1.020803   1.9036964]\n",
      "19\t0.01\t[-1.020123   1.9137299]\n",
      "\n",
      "True w\t\t [-1.  2.]\n",
      "estimated w\t [-1.020123   1.9137299]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.1\n",
    "\n",
    "linear_module = nn.Linear(d, 1, bias=False)\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "\n",
    "print('iter,\\tloss,\\tw')\n",
    "\n",
    "for i in range(20):\n",
    "    y_hat = linear_module(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    print(f'{i}\\t{loss.item():.2f}\\t{linear_module.weight.view(2).detach().numpy()}')\n",
    "\n",
    "print('\\nTrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Linear regression using SGD\n",
    "\n",
    "In the previous examples, we computed the average gradient over the entire dataset(Gradient Descent). We can implement\n",
    "Stochastic Gradient Descent with a simple modification."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss,\tw\n",
      "0,\t4.46,\t[-0.20530999  0.66900945]\n",
      "20,\t1.28,\t[-0.3492172  0.8908058]\n",
      "40,\t0.73,\t[-0.513422   1.1883926]\n",
      "60,\t0.51,\t[-0.6704745  1.5351907]\n",
      "80,\t0.16,\t[-0.7813061  1.6464837]\n",
      "100,\t0.20,\t[-0.8568147  1.7569876]\n",
      "120,\t0.03,\t[-0.90830195  1.8347709 ]\n",
      "140,\t0.00,\t[-0.9449066  1.888105 ]\n",
      "160,\t0.00,\t[-0.96574944  1.9163204 ]\n",
      "180,\t0.01,\t[-0.98202056  1.9221277 ]\n",
      "\n",
      "True w\t\t [-1.  2.]\n",
      "estimated w\t [-0.98299205  1.9443793 ]\n"
     ]
    }
   ],
   "source": [
    "step_size = 0.01\n",
    "\n",
    "linear_module = nn.Linear(d, 1)\n",
    "loss_func = nn.MSELoss()\n",
    "optim = torch.optim.SGD(linear_module.parameters(), lr=step_size)\n",
    "print('iter,\\tloss,\\tw')\n",
    "for i in range(200):\n",
    "    rand_idx = np.random.choice(n)  # take a random point from the dataset\n",
    "    x = X[rand_idx]\n",
    "    y_hat = linear_module(x)\n",
    "    loss = loss_func(y_hat, y[rand_idx])  # only compute the loss on the single point\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % 20 == 0:\n",
    "        print(f'{i},\\t{loss.item():.2f},\\t{linear_module.weight.view(2).detach().numpy()}')\n",
    "\n",
    "print('\\nTrue w\\t\\t', true_w.view(2).numpy())\n",
    "print('estimated w\\t', linear_module.weight.view(2).detach().numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Neural Network Basics in PyTorch\n",
    "\n",
    "Let's consider the dataset from hw3. We will try and fit a simple neural network to the data."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "d = 1\n",
    "n = 200\n",
    "X = torch.rand(n, d)\n",
    "y = 4 * torch.sin(np.pi * X) * torch.cos(6 * np.pi * X ** 2)\n",
    "\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.title('plot of $f(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('$y$')\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we define a simple two hidden layer neural network with Tanh activations. There are a few hyper parameters to play with\n",
    "to get a feel for how they change the results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss\n",
      "0,\t3.99\n",
      "600,\t3.70\n",
      "1200,\t2.45\n",
      "1800,\t1.13\n",
      "2400,\t0.93\n",
      "3000,\t0.70\n",
      "3600,\t0.29\n",
      "4200,\t0.09\n",
      "4800,\t0.08\n",
      "5400,\t0.07\n"
     ]
    }
   ],
   "source": [
    "# feel free to play with these parameters\n",
    "\n",
    "step_size = 0.05\n",
    "n_epochs = 6000\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "d_out = 1\n",
    "\n",
    "neural_network = nn.Sequential(\n",
    "    nn.Linear(d, n_hidden_1),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(n_hidden_1, n_hidden_2),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(n_hidden_2, d_out)\n",
    ")\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size)\n",
    "print('iter,\\tloss')\n",
    "for i in range(n_epochs):\n",
    "    y_hat = neural_network(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % (n_epochs // 10) == 0:\n",
    "        print(f'{i},\\t{loss.item():.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
    "y_hat = neural_network(X_grid)\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
    "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.xlabel('$y$')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Things might help on the homework\n",
    "There are other optimization algorithms besides stochastic gradient descent. One is a modification of SGD called momentum.\n",
    "We won't get into it here, but if you would like to read more, [here](https://d2l.ai/chapter_optimization/momentum.html) is a good place to start.\n",
    "\n",
    "We only change the step size and add the momentum keyword argument to the optimizer. Notice how it reduces the training loss\n",
    "in fewer iterations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter,\tloss\n",
      "0,\t3.98\n",
      "150,\t2.77\n",
      "300,\t0.84\n",
      "450,\t0.26\n",
      "600,\t0.06\n",
      "750,\t0.06\n",
      "900,\t0.01\n",
      "1050,\t0.00\n",
      "1200,\t0.00\n",
      "1350,\t0.00\n"
     ]
    }
   ],
   "source": [
    "# feel free to play with these parameters\n",
    "\n",
    "step_size = 0.05\n",
    "momentum = 0.9\n",
    "n_epochs = 1500\n",
    "n_hidden_1 = 32\n",
    "n_hidden_2 = 32\n",
    "d_out = 1\n",
    "\n",
    "neural_network = nn.Sequential(\n",
    "    nn.Linear(d, n_hidden_1),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(n_hidden_1, n_hidden_2),\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(n_hidden_2, d_out)\n",
    ")\n",
    "\n",
    "loss_func = nn.MSELoss()\n",
    "\n",
    "optim = torch.optim.SGD(neural_network.parameters(), lr=step_size, momentum=momentum)\n",
    "print('iter,\\tloss')\n",
    "for i in range(n_epochs):\n",
    "    y_hat = neural_network(X)\n",
    "    loss = loss_func(y_hat, y)\n",
    "    optim.zero_grad()\n",
    "    loss.backward()\n",
    "    optim.step()\n",
    "\n",
    "    if i % (n_epochs // 10) == 0:\n",
    "        print(f'{i},\\t{loss.item():.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_grid = torch.from_numpy(np.linspace(0,1,50)).float().view(-1, d)\n",
    "y_hat = neural_network(X_grid)\n",
    "plt.scatter(X.numpy(), y.numpy())\n",
    "plt.plot(X_grid.detach().numpy(), y_hat.detach().numpy(), 'r')\n",
    "plt.title('plot of $f(x)$ and $\\hat{f}(x)$')\n",
    "plt.xlabel('$x$')\n",
    "plt.xlabel('$y$')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## CrossEntropyLoss\n",
    "\n",
    "So far, we have been considering regression tasks and have used the `MSELoss` module. For the homework, we will be performing\n",
    "a classification task and will use the cross entropy loss.\n",
    "\n",
    "PyTorch implements a version of the cross entropy loss in one module called `CrossEntropyLoss`. Its usage is slightly\n",
    "different than MSE, so we will break it down here.\n",
    "\n",
    "* input: The first parameter to CrossEntropyLoss is the output of our network. It expects a real valued tensor of dimensions($N, C$)\n",
    "where $N$ is the minibatch size and $C$ is the number of classes. In our case $N=3$ and $C=2$. The values along the second\n",
    "dimension correspond to raw unnormalized scores for each class. The CrossEntropyLoss module does the softmax calculation for us,\n",
    "so we do not need to apply our own softmax to the output of our neural network.\n",
    "* output: The second parameter to CrossEntropyLoss is the true label. It expects an integer valued tensor of dimension($N$). The integer\n",
    "* at each element corresponds to the correct class. In our case, the \"correct\" class labels are class 0, class 1, and class -1.\n",
    "\n",
    "Try out the loss function on three toy predictions. The true class labels are $y=[1,1,0]$. The first two examples correspond to predictions\n",
    "that are \"correct\" in that they have higher raw scores for the correct class. The second example is \"more confident\" in the prediction, leading\n",
    "to a smaller loss. The last two examples are incorrect predictions with lower and higher confidence respectively."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1269)\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = torch.tensor([[-1., 1], [-1, 1], [1, -1]])  # raw scores correspond to the correct class\n",
    "# input = torch.tensor([[-3., 3], [-3, 3], [3, -3]])  # raw scores correspond to the correct class with higher confidence\n",
    "# input = torch.tensor([[1., -1], [1, -1], [-1, 1]])  # raw scores correspond to the incorrect class\n",
    "# input = torch.tensor([[3., -3], [3, -3], [-3, 3]])  # raw scores correspond to the incorrect class with incorrectly placed confidence\n",
    "\n",
    "target = torch.tensor([1, 1, 0])\n",
    "output = loss(input, target)\n",
    "print(output)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convolutions\n",
    "\n",
    "When working with images, we often want to use convolutions to extract features using convolutions. PyTorch implements this\n",
    "for us in the `torch.nn.Conv2d` module. It expects the input to have a specific dimension ($N, C_{in}, H_{in}, W_{in})$\n",
    "where $N$ is batch size, $C_{in}$ is the number of channels the image has, and $H_{in}, W_{in}$ are the image height and\n",
    "width respectively.\n",
    "\n",
    "We can modify the convolution to have different properties with the parameters:\n",
    "* kernel_size\n",
    "* stride\n",
    "* padding\n",
    "\n",
    "They can change the output dimension so be careful.\n",
    "\n",
    "See the [torch.nn.Conv2d.docs](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) for more information."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To illustrate what the Conv2d module is doing. Let's set the conv weights manually to a Gaussian blur kernel.\n",
    "\n",
    "We can see that it applies the kernel to the image."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "I = Image.open('./mnist/train/3/7.png')\n",
    "image = np.array(I).astype(np.float32)\n",
    "image_torch = torch.from_numpy(image).view(1,1,28,28)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# a gaussian blur kernel\n",
    "gaussian_kernel = torch.tensor([[1.,2,1], [2,4,2], [1,2,1]])/16.0\n",
    "\n",
    "conv = nn.Conv2d(1,1,3)\n",
    "# manually set the conv weight\n",
    "conv.weight.data[:] = gaussian_kernel\n",
    "\n",
    "convolved = conv(image_torch)\n",
    "\n",
    "plt.title(\"original image\")\n",
    "plt.imshow(image_torch.view(28,28).detach().numpy())\n",
    "plt.show()\n",
    "\n",
    "plt.title(\"blurred image\")\n",
    "plt.imshow(convolved.view(26, 26).detach().numpy())\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see, the image is blurred as expected.\n",
    "\n",
    "In practice, we learn many kernels at a time. In this example, we take in an RGB image (3 channels) and output a 16 channel\n",
    "image. After an activation function, that could be used as input to another ConV2d module."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im shape: torch.Size([4, 3, 32, 32])\n",
      "convolved im shape: torch.Size([4, 16, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "im_channels = 3  # if we are working with RGB images, there are 3 input channels, with black and white, 1\n",
    "out_channels = 16  # this is a hyperparameter we can tune\n",
    "kernel_size = 3  # this is another hyperparameter we can tune\n",
    "batch_size = 4\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "\n",
    "im = torch.randn(batch_size, im_channels, image_width, image_height)\n",
    "\n",
    "m = nn.Conv2d(im_channels, out_channels, image_width, image_height)\n",
    "convolved = m(im)\n",
    "\n",
    "print(f'im shape: {im.shape}')\n",
    "print(f'convolved im shape: {convolved.shape}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Useful links:\n",
    "\n",
    "* [60 minutes PyTorch Tutorial](https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html)\n",
    "* [PyTorch Docs](https://pytorch.org/docs/stable/index.html)\n",
    "* [Lecture notes on Auto-Diff]()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Custom Datasets, DataLoaders\n",
    "\n",
    "This is modified from pytorch official tutorial. **Author**: `Sasank Chilankurthy <https://chsasank.github.io>`\n",
    "\n",
    "A lot of effort in solving any machine learning problem goes into preparing the data. PyTorch provides many tools to make\n",
    "data loading easy and hopefully, to make your code more readable. In this tutorial, we will see how to load and preprocess/augment\n",
    "data from a non trivial dataset.\n",
    "\n",
    "### Dataset class\n",
    "\n",
    "`torch.utils.data.Dataset` is an abstract class representing a dataset. Your custom dataset should inherit `Dataset` and override\n",
    "the following methods.\n",
    "\n",
    "* `__len__` so that `len(dataset)` returns the size of the dataset.\n",
    "* `__getitem__` to support the indexing such that dataset[1] can be used to get i'th sample\n",
    "\n",
    "Let's create a dataset class for our face landmarks dataset. We will read the csv in `__init__` but leave the reading of\n",
    "images to `__getitem__`. This is memory efficient because all the images are not stored in the memory at once but read as required.\n",
    "\n",
    "Sample of our dataset will be a dict {'image': image, 'landmarks': landmarks}. Our dataset will take an optional argument\n",
    "`transform` so that any required processing can be applied on the sample. We will see the usefulness of transform in the next\n",
    "section."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class FakeDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "However, we are losing a lot of features by using a simple `for` loop to iterate over the data. In particular, we are missing\n",
    "out on:\n",
    "\n",
    "* Batching the data\n",
    "* Shuffling the data\n",
    "* Load the data in parallel using `multiprocessing` workers.\n",
    "\n",
    "`torch.utils.data.DataLoader` is an iterator which provides all these features. Parameters used below should be clear.\n",
    "One parameter of interest is `collate_fn`. You can specify how exactly the samples need to be batched using `collate_fn`.\n",
    "However, default collate should work fine for most use cases."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [tensor([[0.1096, 0.4694, 0.7044, 0.3765, 0.8890, 0.9266, 0.2414, 0.1361, 0.3555,\n",
      "         0.6641],\n",
      "        [0.1505, 0.9721, 0.3268, 0.8636, 0.4060, 0.1426, 0.2754, 0.0926, 0.8451,\n",
      "         0.1824],\n",
      "        [0.5439, 0.1739, 0.6939, 0.3658, 0.5159, 0.9156, 0.0107, 0.5253, 0.1156,\n",
      "         0.4393],\n",
      "        [0.0165, 0.3028, 0.3071, 0.0787, 0.2653, 0.3550, 0.3574, 0.0368, 0.0728,\n",
      "         0.8916]], dtype=torch.float64), tensor([0.2701, 0.7661, 0.1617, 0.1207], dtype=torch.float64)]\n",
      "1 [tensor([[0.0472, 0.2678, 0.7080, 0.2435, 0.6636, 0.8487, 0.3345, 0.3422, 0.7687,\n",
      "         0.3709],\n",
      "        [0.0274, 0.2815, 0.4425, 0.2692, 0.4284, 0.3600, 0.6660, 0.2705, 0.7473,\n",
      "         0.2071],\n",
      "        [0.6278, 0.0859, 0.0657, 0.6674, 0.6366, 0.9306, 0.8121, 0.6326, 0.5322,\n",
      "         0.7793],\n",
      "        [0.0705, 0.8939, 0.1630, 0.9421, 0.4714, 0.8645, 0.1503, 0.4629, 0.6484,\n",
      "         0.6583]], dtype=torch.float64), tensor([0.0040, 0.9358, 0.9702, 0.7861], dtype=torch.float64)]\n",
      "2 [tensor([[0.0795, 0.8094, 0.9198, 0.5961, 0.0574, 0.6314, 0.6500, 0.2977, 0.3418,\n",
      "         0.7521],\n",
      "        [0.6150, 0.6825, 0.1255, 0.7408, 0.5374, 0.0448, 0.4369, 0.7070, 0.6105,\n",
      "         0.2682],\n",
      "        [0.5691, 0.1234, 0.0489, 0.6661, 0.6113, 0.6277, 0.0384, 0.6170, 0.2797,\n",
      "         0.8429],\n",
      "        [0.3773, 0.7661, 0.9189, 0.0614, 0.9269, 0.1185, 0.6387, 0.1429, 0.6989,\n",
      "         0.3441]], dtype=torch.float64), tensor([0.6891, 0.2601, 0.3899, 0.0164], dtype=torch.float64)]\n",
      "3 [tensor([[0.5961, 0.1317, 0.5008, 0.0683, 0.5264, 0.8927, 0.2962, 0.2142, 0.7640,\n",
      "         0.8714],\n",
      "        [0.3348, 0.1017, 0.6351, 0.7048, 0.8362, 0.4930, 0.7561, 0.2674, 0.9701,\n",
      "         0.8510],\n",
      "        [0.7553, 0.7957, 0.3804, 0.9051, 0.6033, 0.3121, 0.1475, 0.6260, 0.8481,\n",
      "         0.0456],\n",
      "        [0.4420, 0.6948, 0.1094, 0.5931, 0.7619, 0.4407, 0.4690, 0.3976, 0.9607,\n",
      "         0.3494]], dtype=torch.float64), tensor([0.8594, 0.3492, 0.2310, 0.1883], dtype=torch.float64)]\n",
      "4 [tensor([[0.5625, 0.4209, 0.3199, 0.5329, 0.4318, 0.4624, 0.7504, 0.0850, 0.8262,\n",
      "         0.8674],\n",
      "        [0.7651, 0.3097, 0.8265, 0.7565, 0.3180, 0.9248, 0.9444, 0.4895, 0.4972,\n",
      "         0.6315],\n",
      "        [0.1328, 0.4722, 0.4579, 0.2818, 0.5141, 0.8366, 0.0479, 0.0689, 0.7267,\n",
      "         0.3794],\n",
      "        [0.6050, 0.2824, 0.6153, 0.2513, 0.0531, 0.0236, 0.7016, 0.6394, 0.9860,\n",
      "         0.4539]], dtype=torch.float64), tensor([0.6624, 0.8146, 0.3083, 0.9452], dtype=torch.float64)]\n",
      "5 [tensor([[0.8506, 0.4169, 0.4541, 0.9331, 0.0052, 0.1280, 0.9007, 0.1913, 0.8718,\n",
      "         0.0106],\n",
      "        [0.5042, 0.4699, 0.3214, 0.7640, 0.5101, 0.6616, 0.3617, 0.4770, 0.0069,\n",
      "         0.1894],\n",
      "        [0.6574, 0.5226, 0.4919, 0.2658, 0.3278, 0.4690, 0.0562, 0.9769, 0.1475,\n",
      "         0.5129],\n",
      "        [0.2407, 0.3158, 0.8096, 0.1740, 0.9177, 0.7346, 0.3027, 0.5294, 0.2325,\n",
      "         0.8409]], dtype=torch.float64), tensor([0.6756, 0.4412, 0.3191, 0.3310], dtype=torch.float64)]\n",
      "6 [tensor([[0.1415, 0.0567, 0.5027, 0.6150, 0.1651, 0.4861, 0.4452, 0.6551, 0.6557,\n",
      "         0.7662],\n",
      "        [0.5806, 0.0531, 0.8747, 0.0568, 0.1727, 0.7886, 0.5517, 0.1274, 0.0775,\n",
      "         0.2411],\n",
      "        [0.5321, 0.4342, 0.0405, 0.1812, 0.6136, 0.7870, 0.0483, 0.9592, 0.4478,\n",
      "         0.5764],\n",
      "        [0.6713, 0.4263, 0.9188, 0.9392, 0.6510, 0.8450, 0.1234, 0.0928, 0.8625,\n",
      "         0.0309]], dtype=torch.float64), tensor([0.1673, 0.1575, 0.8922, 0.0337], dtype=torch.float64)]\n",
      "7 [tensor([[0.6934, 0.8673, 0.6935, 0.4884, 0.7295, 0.3680, 0.1332, 0.1841, 0.8962,\n",
      "         0.7861],\n",
      "        [0.9852, 0.7606, 0.0070, 0.6510, 0.2410, 0.3949, 0.1414, 0.7690, 0.8134,\n",
      "         0.7123],\n",
      "        [0.5660, 0.5365, 0.7909, 0.4810, 0.2659, 0.1149, 0.3142, 0.5249, 0.2611,\n",
      "         0.9927],\n",
      "        [0.1366, 0.9362, 0.8221, 0.4098, 0.0233, 0.8347, 0.3028, 0.7414, 0.2492,\n",
      "         0.3986]], dtype=torch.float64), tensor([0.0302, 0.8446, 0.2815, 0.1860], dtype=torch.float64)]\n",
      "8 [tensor([[0.2921, 0.9617, 0.9515, 0.3262, 0.4368, 0.5069, 0.7174, 0.9699, 0.8135,\n",
      "         0.2042],\n",
      "        [0.8126, 0.4741, 0.5860, 0.3143, 0.0428, 0.0722, 0.0376, 0.9781, 0.0124,\n",
      "         0.2722],\n",
      "        [0.9219, 0.4175, 0.7378, 0.7466, 0.6516, 0.3478, 0.3196, 0.4792, 0.0107,\n",
      "         0.0097],\n",
      "        [0.3676, 0.1686, 0.0707, 0.4301, 0.8522, 0.6364, 0.6080, 0.8737, 0.3691,\n",
      "         0.1897]], dtype=torch.float64), tensor([0.8708, 0.4335, 0.3341, 0.2156], dtype=torch.float64)]\n",
      "9 [tensor([[0.8425, 0.0163, 0.0450, 0.9658, 0.1704, 0.7332, 0.5599, 0.3465, 0.5721,\n",
      "         0.3130],\n",
      "        [0.3985, 0.6418, 0.9978, 0.6291, 0.6545, 0.5499, 0.6170, 0.3744, 0.1309,\n",
      "         0.0333],\n",
      "        [0.6515, 0.9134, 0.5027, 0.7137, 0.3813, 0.0376, 0.6971, 0.9692, 0.9135,\n",
      "         0.2692],\n",
      "        [0.7485, 0.2783, 0.3977, 0.0927, 0.1109, 0.4401, 0.9317, 0.4913, 0.9146,\n",
      "         0.5833]], dtype=torch.float64), tensor([0.3623, 0.9767, 0.6051, 0.5321], dtype=torch.float64)]\n",
      "10 [tensor([[0.1370, 0.7772, 0.2095, 0.0615, 0.9563, 0.1148, 0.7654, 0.8568, 0.8793,\n",
      "         0.3518],\n",
      "        [0.4609, 0.6859, 0.3709, 0.9270, 0.6991, 0.5749, 0.8408, 0.4865, 0.5438,\n",
      "         0.6000],\n",
      "        [0.2575, 0.8604, 0.1631, 0.3485, 0.5333, 0.5776, 0.7931, 0.6992, 0.4117,\n",
      "         0.0477],\n",
      "        [0.9241, 0.5794, 0.1106, 0.4831, 0.1394, 0.8072, 0.4977, 0.0555, 0.7470,\n",
      "         0.6890]], dtype=torch.float64), tensor([0.0032, 0.8094, 0.3106, 0.0983], dtype=torch.float64)]\n",
      "11 [tensor([[0.3225, 0.1331, 0.9460, 0.9248, 0.6805, 0.3465, 0.6849, 0.1555, 0.6478,\n",
      "         0.7804],\n",
      "        [0.2653, 0.5330, 0.0414, 0.4293, 0.3036, 0.1316, 0.0314, 0.6894, 0.7553,\n",
      "         0.2532],\n",
      "        [0.1443, 0.5263, 0.4120, 0.3804, 0.8041, 0.9519, 0.1409, 0.5286, 0.9267,\n",
      "         0.2848],\n",
      "        [0.7059, 0.0629, 0.4574, 0.6665, 0.9461, 0.6405, 0.6298, 0.0565, 0.9597,\n",
      "         0.4506]], dtype=torch.float64), tensor([0.0759, 0.0190, 0.4732, 0.9747], dtype=torch.float64)]\n",
      "12 [tensor([[0.4232, 0.2060, 0.8339, 0.6456, 0.2742, 0.0868, 0.9288, 0.2806, 0.1588,\n",
      "         0.8433],\n",
      "        [0.3525, 0.3487, 0.2770, 0.5047, 0.1117, 0.9636, 0.4308, 0.3456, 0.0113,\n",
      "         0.2805],\n",
      "        [0.4832, 0.9956, 0.4878, 0.2249, 0.9667, 0.6957, 0.0909, 0.6688, 0.8366,\n",
      "         0.0182],\n",
      "        [0.2442, 0.1764, 0.6082, 0.0751, 0.6153, 0.5185, 0.6593, 0.6469, 0.2874,\n",
      "         0.4393]], dtype=torch.float64), tensor([0.4983, 0.4506, 0.3888, 0.0552], dtype=torch.float64)]\n",
      "13 [tensor([[0.2514, 0.5027, 0.7723, 0.5894, 0.3749, 0.9916, 0.5685, 0.2184, 0.4930,\n",
      "         0.4290],\n",
      "        [0.5355, 0.7904, 0.9605, 0.7997, 0.1974, 0.2357, 0.5871, 0.5880, 0.8157,\n",
      "         0.7967],\n",
      "        [0.1089, 0.5596, 0.5591, 0.7019, 0.5667, 0.2379, 0.3286, 0.0240, 0.3211,\n",
      "         0.1834],\n",
      "        [0.9117, 0.1700, 0.2482, 0.3003, 0.1531, 0.6073, 0.5338, 0.5332, 0.2620,\n",
      "         0.0839]], dtype=torch.float64), tensor([0.3861, 0.3752, 0.3808, 0.0576], dtype=torch.float64)]\n",
      "14 [tensor([[0.3854, 0.9316, 0.0298, 0.9188, 0.8910, 0.3670, 0.8487, 0.1697, 0.0127,\n",
      "         0.0498],\n",
      "        [0.3914, 0.0533, 0.7894, 0.8275, 0.7835, 0.2978, 0.4156, 0.8235, 0.9098,\n",
      "         0.8376],\n",
      "        [0.7026, 0.0047, 0.9629, 0.5305, 0.8144, 0.2466, 0.7914, 0.4742, 0.6611,\n",
      "         0.9934],\n",
      "        [0.0994, 0.4514, 0.3857, 0.9796, 0.9205, 0.1876, 0.3074, 0.2653, 0.4389,\n",
      "         0.1293]], dtype=torch.float64), tensor([0.0839, 0.8951, 0.1524, 0.2245], dtype=torch.float64)]\n",
      "15 [tensor([[0.3471, 0.9848, 0.1266, 0.3642, 0.3110, 0.2262, 0.7783, 0.4433, 0.5535,\n",
      "         0.4736],\n",
      "        [0.1141, 0.1068, 0.5190, 0.8968, 0.4951, 0.1997, 0.6193, 0.2545, 0.8648,\n",
      "         0.8976],\n",
      "        [0.3322, 0.7527, 0.8107, 0.2407, 0.2330, 0.0650, 0.1372, 0.2534, 0.4211,\n",
      "         0.1260],\n",
      "        [0.3332, 0.0981, 0.7359, 0.7838, 0.3023, 0.2381, 0.5067, 0.4706, 0.2707,\n",
      "         0.3132]], dtype=torch.float64), tensor([0.0902, 0.8928, 0.7878, 0.4883], dtype=torch.float64)]\n",
      "16 [tensor([[0.6240, 0.6081, 0.1885, 0.8287, 0.0992, 0.9690, 0.7310, 0.4237, 0.0929,\n",
      "         0.3810],\n",
      "        [0.1478, 0.4510, 0.5293, 0.0144, 0.6534, 0.0011, 0.7619, 0.8707, 0.0184,\n",
      "         0.0679],\n",
      "        [0.3428, 0.9303, 0.4622, 0.7690, 0.5182, 0.2178, 0.8088, 0.3814, 0.2451,\n",
      "         0.0097],\n",
      "        [0.4786, 0.1964, 0.8945, 0.9900, 0.8276, 0.1961, 0.2638, 0.0117, 0.1773,\n",
      "         0.6262]], dtype=torch.float64), tensor([0.2295, 0.9799, 0.3401, 0.0566], dtype=torch.float64)]\n",
      "17 [tensor([[0.3544, 0.1138, 0.4130, 0.6864, 0.0309, 0.2801, 0.9899, 0.4980, 0.8004,\n",
      "         0.2637],\n",
      "        [0.6947, 0.4833, 0.4664, 0.0637, 0.6154, 0.3276, 0.2890, 0.9505, 0.2479,\n",
      "         0.4722],\n",
      "        [0.1796, 0.2674, 0.7746, 0.9959, 0.3893, 0.6051, 0.6899, 0.3247, 0.2102,\n",
      "         0.8673],\n",
      "        [0.9806, 0.3530, 0.0961, 0.5138, 0.8475, 0.7146, 0.5949, 0.2177, 0.5165,\n",
      "         0.7706]], dtype=torch.float64), tensor([0.3185, 0.1866, 0.3140, 0.8239], dtype=torch.float64)]\n",
      "18 [tensor([[0.0157, 0.9246, 0.2020, 0.1813, 0.5590, 0.1894, 0.8663, 0.3976, 0.6099,\n",
      "         0.7796],\n",
      "        [0.1269, 0.5661, 0.6663, 0.0428, 0.6780, 0.2926, 0.7766, 0.1815, 0.7354,\n",
      "         0.6291],\n",
      "        [0.7997, 0.7779, 0.2931, 0.6034, 0.3622, 0.1584, 0.6144, 0.7697, 0.3829,\n",
      "         0.0093],\n",
      "        [0.8435, 0.2153, 0.4496, 0.2253, 0.4997, 0.3479, 0.4391, 0.0605, 0.4542,\n",
      "         0.0157]], dtype=torch.float64), tensor([0.1214, 0.6234, 0.2867, 0.6350], dtype=torch.float64)]\n",
      "19 [tensor([[0.7834, 0.7959, 0.4286, 0.5653, 0.3529, 0.3601, 0.0417, 0.5342, 0.4847,\n",
      "         0.0560],\n",
      "        [0.4771, 0.3198, 0.2225, 0.2465, 0.5702, 0.4464, 0.7550, 0.1298, 0.1753,\n",
      "         0.1040],\n",
      "        [0.3330, 0.9045, 0.2981, 0.6869, 0.8339, 0.6206, 0.7687, 0.8025, 0.1287,\n",
      "         0.2582],\n",
      "        [0.0633, 0.2424, 0.2661, 0.7229, 0.8196, 0.0043, 0.3061, 0.9725, 0.4043,\n",
      "         0.5097]], dtype=torch.float64), tensor([0.0361, 0.5800, 0.4160, 0.4057], dtype=torch.float64)]\n",
      "20 [tensor([[0.2195, 0.3428, 0.2049, 0.9051, 0.9741, 0.3217, 0.1570, 0.6321, 0.9287,\n",
      "         0.0520],\n",
      "        [0.7630, 0.1256, 0.6109, 0.5586, 0.9137, 0.5597, 0.6269, 0.3198, 0.3077,\n",
      "         0.3593],\n",
      "        [0.2460, 0.8893, 0.5499, 0.0054, 0.8566, 0.2870, 0.2730, 0.5990, 0.5467,\n",
      "         0.3042],\n",
      "        [0.1630, 0.2736, 0.0070, 0.1457, 0.0807, 0.6849, 0.8761, 0.0502, 0.7291,\n",
      "         0.2466]], dtype=torch.float64), tensor([0.1052, 0.4832, 0.3607, 0.6671], dtype=torch.float64)]\n",
      "21 [tensor([[0.0431, 0.4885, 0.0495, 0.2853, 0.8376, 0.3061, 0.0888, 0.8225, 0.8141,\n",
      "         0.8305],\n",
      "        [0.5713, 0.6165, 0.7750, 0.5141, 0.1918, 0.8182, 0.5630, 0.2650, 0.9904,\n",
      "         0.0493],\n",
      "        [0.2766, 0.8681, 0.0590, 0.0525, 0.6620, 0.5223, 0.9452, 0.1036, 0.2693,\n",
      "         0.3226],\n",
      "        [0.5955, 0.0951, 0.6246, 0.7979, 0.9589, 0.3035, 0.9799, 0.8582, 0.6784,\n",
      "         0.7507]], dtype=torch.float64), tensor([0.9373, 0.8794, 0.4770, 0.3991], dtype=torch.float64)]\n",
      "22 [tensor([[0.1711, 0.7196, 0.2643, 0.3807, 0.5423, 0.7101, 0.6998, 0.4714, 0.5880,\n",
      "         0.9182],\n",
      "        [0.3207, 0.4271, 0.3206, 0.9046, 0.7617, 0.8463, 0.6925, 0.1443, 0.0974,\n",
      "         0.5341],\n",
      "        [0.3276, 0.4199, 0.6992, 0.4885, 0.0958, 0.6588, 0.2741, 0.4439, 0.1695,\n",
      "         0.8619],\n",
      "        [0.9347, 0.8148, 0.4499, 0.0176, 0.4606, 0.1236, 0.1444, 0.2298, 0.5406,\n",
      "         0.6820]], dtype=torch.float64), tensor([0.5712, 0.8877, 0.3145, 0.6488], dtype=torch.float64)]\n",
      "23 [tensor([[0.4305, 0.7886, 0.6214, 0.4531, 0.4469, 0.7205, 0.1592, 0.1842, 0.5187,\n",
      "         0.6969],\n",
      "        [0.6122, 0.3149, 0.4599, 0.4874, 0.5861, 0.7513, 0.2208, 0.0972, 0.9090,\n",
      "         0.7897],\n",
      "        [0.2729, 0.1071, 0.9125, 0.4087, 0.2112, 0.2144, 0.4645, 0.4689, 0.5563,\n",
      "         0.3527],\n",
      "        [0.1333, 0.8867, 0.5232, 0.9336, 0.1000, 0.0323, 0.3984, 0.9970, 0.4848,\n",
      "         0.4662]], dtype=torch.float64), tensor([0.2027, 0.0727, 0.2831, 0.6319], dtype=torch.float64)]\n",
      "24 [tensor([[0.1754, 0.2864, 0.7618, 0.0244, 0.3647, 0.9209, 0.0891, 0.1538, 0.1855,\n",
      "         0.7084],\n",
      "        [0.7332, 0.8916, 0.8853, 0.7412, 0.7929, 0.9534, 0.1238, 0.0607, 0.1257,\n",
      "         0.0268],\n",
      "        [0.3389, 0.7122, 0.8899, 0.6695, 0.9767, 0.1120, 0.2055, 0.7342, 0.6544,\n",
      "         0.9195],\n",
      "        [0.5020, 0.6228, 0.7321, 0.8117, 0.8293, 0.7492, 0.4505, 0.8574, 0.3756,\n",
      "         0.7858]], dtype=torch.float64), tensor([0.8977, 0.9971, 0.1774, 0.8451], dtype=torch.float64)]\n"
     ]
    }
   ],
   "source": [
    "x = np.random.rand(100, 10)\n",
    "y = np.random.rand(100)\n",
    "\n",
    "dataset = FakeDataset(x, y)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Mixed Presision Training\n",
    "\n",
    "**Author**: Chi-Liang Liu <https://liangtaiwan.github.io> **Ref**: https://github.com/NVIDIA/apex Using mixed precision to train\n",
    "your networks can be:\n",
    "\n",
    "* 2-4x faster\n",
    "* memory-efficient in only 3 lines of Python.\n",
    "\n",
    "## Apex\n",
    "\n",
    "NVIDIA-maintained utilities to streamline mixed precision and distributed training in PyTorch. Some of the code here will be\n",
    "included in upstream PyTorch eventually. The intention of Apex is to make up-to-date utilities available to users as quickly\n",
    "as possible.\n",
    "\n",
    "### apex.amp\n",
    "\n",
    "Amp allows users to easily experiment with different pure and mixed precision modes. Commonly-used default modes are chosen\n",
    "by selecting an 'optimization level' or `opt_level`; each `opt_level` establishes a set of properties that govern Amp's\n",
    "implementation of pure of mixed precision training. Finer-grained control of how a given `opt_level` behaves can be achieved\n",
    "by passing values for particular properties directly to `amp.initialize`. These manually specified values overrides the defaults\n",
    "established by the `opt_level`.\n",
    "\n",
    "Note: You should install the latest version of apex!!!!"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'UnencryptedCookieSessionFactoryConfig' from 'pyramid.session' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_10628/3887502553.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mapex\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mamp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;31m# Declare model and optimizer as usual, with default {FP32} precision\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnn\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m10\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m100\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcuda\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0moptimizer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mSGD\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mparameters\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlr\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m1e-3\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/anaconda3/envs/pytorch/lib/python3.8/site-packages/apex/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     11\u001B[0m                                 ISessionFactory)\n\u001B[1;32m     12\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyramid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msecurity\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mNO_PERMISSION_REQUIRED\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 13\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mpyramid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msession\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mUnencryptedCookieSessionFactoryConfig\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     14\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpyramid\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msettings\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0masbool\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     15\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'UnencryptedCookieSessionFactoryConfig' from 'pyramid.session' (unknown location)"
     ]
    }
   ],
   "source": [
    "# below are only the example codes\n",
    "\n",
    "from apex import amp\n",
    "\n",
    "# Declare model and optimizer as usual, with default {FP32} precision\n",
    "model = torch.nn.Linear(10, 100).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# Allow Amp to perform casts as required by the opt_level\n",
    "model, optimizer = amp.initialize(model, optimizer, optimizer=\"01\")\n",
    "\n",
    "# loss.backward() becomes:\n",
    "with amp.scale_loss(loss, optimizer) as scaled_loss:\n",
    "    scaled_loss.backward()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}